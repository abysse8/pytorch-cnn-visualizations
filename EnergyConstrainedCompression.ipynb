{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EnergyConstrainedCompression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panda1230/pytorch-cnn-visualizations/blob/master/EnergyConstrainedCompression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiaeQP2rEpP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import sys\n",
        "import copy\n",
        "from models import get_net_model\n",
        "from proj_utils import fill_model_weights, layers_stat, model_sparsity, filtered_parameters, \\\n",
        "    l0proj, round_model_weights, clamp_model_weights\n",
        "from sa_energy_model import build_energy_info, energy_eval2, energy_eval2_relax, energy_proj2, \\\n",
        "    reset_Xenergy_cache\n",
        "from utils import get_data_loaders, joint_loss, eval_loss_acc1_acc5, model_snapshot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl4qPE6lFFat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net='lenet-5'\n",
        "dataset = 'mnist-32'\n",
        "batch_size= 64\n",
        "val_batch_size=64\n",
        "num_workers =8 \n",
        "epochs =30\n",
        "lr_m = 0.001, #'learning rate'\n",
        "xlr =1e-4 #'learning rate for input mask'\n",
        "l2wd =1e-4 #'l2 weight decay'\n",
        "xl2wd=1e-5 #l2 weight decay (for input mask)'\n",
        "momentum =0.9 #momentum\n",
        "proj_int=10 #'how many batches for each projection'\n",
        "nodp = 1 #action='store_true', help='turn off dropout'\n",
        "input_mask=1 # action='store_true', help='enable input mask'\n",
        "randinit =1 #action='store_true', help='use random init'\n",
        "eval =1 #action='store_true', help='evaluate testset in the begining')\n",
        "#parser.add_argument('--pretrain', default=None, help='file to load pretrained model')\n",
        "#parser.add_argument('--eval', action='store_true', help='evaluate testset in the begining')\n",
        "#parser.add_argument('--seed', type=int, default=117, help='random seed')\n",
        "log_interval =100 # help='how many batches to wait before logging training status')\n",
        "test_interval = 1 # help='how many epochs to wait before another test')\n",
        "save_interval=10# help='how many epochs to wait before save a model')\n",
        "logdir = './sample_data/' #help='folder to save to the log'\n",
        "distill=0.5 # help='distill loss weight')\n",
        "budget=0.2 #help='energy budget (relative)')\n",
        "exp_bdecay = 1 #action='store_true', help='exponential budget decay')\n",
        "mgpu =1 # action='store_true', help='enable using multiple gpus')\n",
        "skip1 = 1 #action='store_true', help='skip the first W update')\n",
        "cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2z8JzOIFY8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up random seeds\n",
        "torch.manual_seed(117)\n",
        "if cuda:\n",
        "  torch.cuda.manual_seed(117)\n",
        "  np.random.seed(117)\n",
        "  random.seed(117)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrclXY9xK541",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get training and validation data loaders\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.Resize(32),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./sample_data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "tr_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=num_workers)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./sample_data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "val_loader = torch.utils.data.DataLoader(testset, batch_size=val_batch_size,\n",
        "                                         shuffle=False, num_workers=num_workers)\n",
        "\n",
        "train_loader4eval = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFIfOuPxMm5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get network model\n",
        "model, teacher_model = get_net_model(net=net, pretrained_dataset=dataset, dropout=(not nodp),\n",
        "                                         pretrained=not randinit, input_mask=input_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5JKdWQ9NwMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "7b0e8831-89f3-4823-a3ce-646d5ffed4e9"
      },
      "source": [
        "model"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyLeNet5(\n",
              "  (features): Sequential(\n",
              "    (0): SparseConv2d(32, 32, 1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): SparseConv2d(14, 14, 6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAvhkr9iN2e5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "475677dd-463f-44aa-d0aa-5a1a2f1be4fe"
      },
      "source": [
        "teacher_model"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyLeNet5(\n",
              "  (features): Sequential(\n",
              "    (0): FixHWConv2d(32, 32, 1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): FixHWConv2d(14, 14, 6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIPPBdfPN63p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c8bdd5b5-6470-460d-acfd-8a9f48ce59ee"
      },
      "source": [
        " # for energy estimate\n",
        "print('================model energy summary================')\n",
        "energy_info = build_energy_info(model)\n",
        "energy_estimator = lambda m: sum(energy_eval2(m, energy_info, verbose=False).values())\n",
        "energy_estimator_relaxed = lambda m: sum(energy_eval2_relax(m, energy_info, verbose=False).values())\n",
        "\n",
        "reset_Xenergy_cache(energy_info)\n",
        "cur_energy = sum(energy_eval2(model, energy_info, verbose=True).values())\n",
        "cur_energy_relaxed = energy_estimator_relaxed(model)\n",
        "\n",
        "dense_model = fill_model_weights(copy.deepcopy(model), 1.0)\n",
        "budget_ub = energy_estimator_relaxed(dense_model)\n",
        "zero_model = fill_model_weights(copy.deepcopy(model), 0.0)\n",
        "budget_lb = energy_estimator_relaxed(zero_model)\n",
        "\n",
        "del zero_model, dense_model\n",
        "budget = max(budget, budget_lb / budget_ub)\n",
        "\n",
        "proj_func = lambda m, budget, grad=False, in_place=True: energy_proj2(m, energy_info, budget, grad=grad,\n",
        "                                                                         in_place=in_place, param_name='weight')\n",
        "print('energy on dense DNN:{:.4e}, on zero DNN:{:.4e}, normalized_lb={:.4e}'.format(budget_ub, budget_lb,\n",
        "                                                                                        budget_lb / budget_ub))\n",
        "print('energy on current DNN:{:.4e}, normalized={:.4e}'.format(cur_energy, cur_energy / budget_ub))\n",
        "print('====================================================')\n",
        "print('current energy {:.4e}, relaxed: {:.4e}'.format(cur_energy, cur_energy_relaxed))\n",
        "netl2wd = l2wd"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================model energy summary================\n",
            "Layer: features.0, input shape: (1, 32, 32), output shape: (6, 28, 28), weight shape: torch.Size([6, 1, 5, 5])\n",
            "Layer: features.0, W_energy=2.07e+05, C_energy=3.53e+05, X_energy=1.38e+06\n",
            "Layer: features.3, input shape: (6, 14, 14), output shape: (16, 10, 10), weight shape: torch.Size([16, 6, 5, 5])\n",
            "Layer: features.3, W_energy=8.50e+05, C_energy=7.20e+05, X_energy=9.75e+05\n",
            "Layer: classifier.0, W_energy=9.94e+06, C_energy=1.44e+05, X_energy=1.74e+05\n",
            "Layer: classifier.2, W_energy=2.09e+06, C_energy=3.02e+04, X_energy=5.52e+04\n",
            "Layer: classifier.4, W_energy=1.74e+05, C_energy=2.52e+03, X_energy=2.01e+04\n",
            "energy on dense DNN:1.7108e+07, on zero DNN:2.6049e+06, normalized_lb=1.5227e-01\n",
            "energy on current DNN:1.7108e+07, normalized=1.0000e+00\n",
            "====================================================\n",
            "current energy 1.7108e+07, relaxed: 1.7108e+07\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DPnKghfOsXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if cuda:\n",
        "  if distill > 0.0:\n",
        "    teacher_model.cuda()\n",
        "    model.cuda()\n",
        "loss_func = lambda m, x, y: joint_loss(model=m, data=x, target=y, teacher_model=teacher_model, distill=distill)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AjAdtyVPLUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8dc5de1f-26ec-4919-9741-39fbb27e3ce4"
      },
      "source": [
        "if eval or dataset != 'imagenet':\n",
        "  val_loss, val_acc1, val_acc5 = eval_loss_acc1_acc5(model, val_loader, loss_func, cuda)\n",
        "  print('**Validation loss:{:.4e}, top-1 accuracy:{:.5f}, top-5 accuracy:{:.5f}'.format(val_loss, val_acc1,\n",
        "                                                                                              val_acc5))\n",
        "# also evaluate training data\n",
        "  tr_loss, tr_acc1, tr_acc5 = eval_loss_acc1_acc5(model, train_loader4eval, loss_func, cuda)\n",
        "  print('###Training loss:{:.4e}, top-1 accuracy:{:.5f}, top-5 accuracy:{:.5f}'.format(tr_loss, tr_acc1, tr_acc5))\n",
        "else:\n",
        "    val_acc1 = 0.0\n",
        "    print('For imagenet, skip the first validation evaluation.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**Validation loss:1.2966e+02, top-1 accuracy:0.05770, top-5 accuracy:0.49600\n",
            "###Training loss:1.2851e+02, top-1 accuracy:0.06018, top-5 accuracy:0.49382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5YYKC3iPltD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "old_file = None\n",
        "\n",
        "energy_step = math.ceil(max(0.0, cur_energy - budget * budget_ub) / ((len(tr_loader) * epochs) / proj_int))\n",
        "\n",
        "energy_decay_factor = min(1.0, (budget * budget_ub) / cur_energy) ** \\\n",
        "                          (1.0 / ((len(tr_loader) * epochs) / proj_int))\n",
        "\n",
        "optimizer = torch.optim.SGD(filtered_parameters(model, param_name='input_mask', inverse=True), lr=0.1, momentum=0.9, weight_decay=netl2wd)\n",
        "if input_mask:\n",
        "  Xoptimizer = torch.optim.Adam(filtered_parameters(model, param_name='input_mask', inverse=False), lr=0.01, weight_decay=xl2wd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQQYzP1ZQSTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cur_budget = cur_energy_relaxed\n",
        "lr = lr_m\n",
        "xlr = xlr\n",
        "cur_sparsity = model_sparsity(model)\n",
        "\n",
        "best_acc_pruned = None\n",
        "Xbudget = 0.9\n",
        "iter_idx = 0\n",
        "\n",
        "W_proj_time = 0.0\n",
        "W_proj_time_cnt = 1e-15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40zehJ4aRi9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d87cb1d-5750-43c4-ff35-18e787b7e2c8"
      },
      "source": [
        "while True:\n",
        "        # update W\n",
        "        if not (skip1 and iter_idx == 0):\n",
        "            t_begin = time.time()\n",
        "            log_tic = t_begin\n",
        "            for epoch in range(epochs):\n",
        "                for batch_idx, (data, target) in enumerate(tr_loader):\n",
        "                    model.train()\n",
        "                    if cuda:\n",
        "                        data, target = data.cuda(), target.cuda()\n",
        "\n",
        "                    loss = loss_func(model, data, target)\n",
        "                    # update network weights\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    if proj_int == 1 or (batch_idx > 0 and batch_idx % args.proj_int == 0) or batch_idx == len(tr_loader) - 1:\n",
        "                        temp_tic = time.time()\n",
        "                        proj_func(model, cur_budget)\n",
        "                        W_proj_time += time.time() - temp_tic\n",
        "                        W_proj_time_cnt += 1\n",
        "                        if epoch == epochs - 1 and batch_idx >= len(tr_loader) - 1 - proj_int:\n",
        "                            cur_budget = budget * budget_ub\n",
        "                        else:\n",
        "                            if exp_bdecay:\n",
        "                                cur_budget = max(cur_budget * energy_decay_factor, budget * budget_ub)\n",
        "                            else:\n",
        "                                cur_budget = max(cur_budget - energy_step, budget * budget_ub)\n",
        "                    print(batch_idx)\n",
        "\n",
        "                    if batch_idx % log_interval == 0:\n",
        "                        print('======================================================')\n",
        "                        print('+-------------- epoch {}, batch {}/{} ----------------+'.format(epoch, batch_idx,\n",
        "                                                                                               len(tr_loader)))\n",
        "                        log_toc = time.time()\n",
        "                        print(\n",
        "                            'primal update: net loss={:.4e}, lr={:.4e}, current normalized budget: {:.4e}, time_elapsed={:.3f}s, averaged projection_time {}'.format(\n",
        "                                loss.item(), optimizer.param_groups[0]['lr'], cur_budget / budget_ub, log_toc - log_tic, W_proj_time / W_proj_time_cnt))\n",
        "                        log_tic = time.time()\n",
        "                        if batch_idx % proj_int == 0:\n",
        "                            cur_sparsity = model_sparsity(model)\n",
        "                        print('sparsity:{}'.format(cur_sparsity))\n",
        "                        print(layers_stat(model, param_names='weight', param_filter=lambda p: p.dim() > 1))\n",
        "                        print('+-----------------------------------------------------+')\n",
        "\n",
        "                cur_energy = energy_estimator(model)\n",
        "                cur_energy_relaxed = energy_estimator_relaxed(model)\n",
        "                cur_sparsity = model_sparsity(model)\n",
        "                if epoch % test_interval == 0:\n",
        "                    val_loss, val_acc1, val_acc5 = eval_loss_acc1_acc5(model, val_loader, loss_func, cuda)\n",
        "\n",
        "                    # also evaluate training data\n",
        "                    tr_loss, tr_acc1, tr_acc5 = eval_loss_acc1_acc5(model, train_loader4eval, loss_func, cuda)\n",
        "                    print('###Training loss:{:.4e}, top-1 accuracy:{:.5f}, top-5 accuracy:{:.5f}'.format(tr_loss, tr_acc1,\n",
        "                                                                                                         tr_acc5))\n",
        "\n",
        "                    print(\n",
        "                        '***Validation loss:{:.4e}, top-1 accuracy:{:.5f}, top-5 accuracy:{:.5f}, current normalized energy:{:.4e}, {:.4e}(relaxed), sparsity: {:.4e}'.format(\n",
        "                            val_loss, val_acc1,\n",
        "                            val_acc5, cur_energy / budget_ub, cur_energy_relaxed / budget_ub, cur_sparsity))\n",
        "                    # save current model\n",
        "                    model_snapshot(model, os.path.join(logdir, 'primal_model_latest.pkl'))\n",
        "\n",
        "                if save_interval > 0 and epoch % save_interval == 0:\n",
        "                    model_snapshot(model, os.path.join(logdir, 'Wprimal_model_epoch{}_{}.pkl'.format(iter_idx, epoch)))\n",
        "\n",
        "                elapse_time = time.time() - t_begin\n",
        "                speed_epoch = elapse_time / (1 + epoch)\n",
        "                eta = speed_epoch * (epochs - epoch)\n",
        "                print(\"Updating Weights, Elapsed {:.2f}s, ets {:.2f}s\".format(elapse_time, eta))\n",
        "\n",
        "        if not input_mask:\n",
        "            print(\"Complete weights training.\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Continue to train input mask.\")\n",
        "\n",
        "        if best_acc_pruned is not None and val_acc1 <= best_acc_pruned:\n",
        "            print(\"Pruned accuracy does not improve, stop here!\")\n",
        "            break\n",
        "        best_acc_pruned = val_acc1\n",
        "\n",
        "        # update X\n",
        "        t_begin = time.time()\n",
        "        log_tic = t_begin\n",
        "        for epoch in range(epochs):\n",
        "            for batch_idx, (data, target) in enumerate(tr_loader):\n",
        "                model.train()\n",
        "                Xoptimizer.param_groups[0]['lr'] = xlr\n",
        "                if cuda:\n",
        "                    data, target = data.cuda(), target.cuda()\n",
        "\n",
        "                loss = loss_func(model, data, target)\n",
        "                # update network weights\n",
        "                Xoptimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                Xoptimizer.step()\n",
        "                clamp_model_weights(model, min=0.0, max=1.0, param_name='input_mask')\n",
        "\n",
        "                if (batch_idx > 0 and batch_idx % proj_int == 0) or batch_idx == len(tr_loader) - 1:\n",
        "                    l0proj(model, Xbudget, param_name='input_mask')\n",
        "\n",
        "                if batch_idx % log_interval == 0:\n",
        "                    print('======================================================')\n",
        "                    print('+-------------- epoch {}, batch {}/{} ----------------+'.format(epoch, batch_idx,\n",
        "                                                                                           len(tr_loader)))\n",
        "                    log_toc = time.time()\n",
        "                    print('primal update: net loss={:.4e}, xlr={:.4e}, time_elapsed={:.3f}s'.format(\n",
        "                            loss.item(), Xoptimizer.param_groups[0]['lr'], log_toc - log_tic))\n",
        "                    log_tic = time.time()\n",
        "                    if batch_idx % proj_int == 0:\n",
        "                        cur_sparsity = model_sparsity(model, param_name='input_mask')\n",
        "                    print('sparsity:{}'.format(cur_sparsity))\n",
        "                    print(layers_stat(model, param_names='input_mask'))\n",
        "                    print('+-----------------------------------------------------+')\n",
        "\n",
        "            cur_energy = energy_estimator(model)\n",
        "            cur_energy_relaxed = energy_estimator_relaxed(model)\n",
        "            cur_sparsity = model_sparsity(model, param_name='input_mask')\n",
        "            if epoch % test_interval == 0:\n",
        "\n",
        "                val_loss, val_acc1, val_acc5 = eval_loss_acc1_acc5(model, val_loader, loss_func, cuda)\n",
        "\n",
        "                # also evaluate training data\n",
        "                tr_loss, tr_acc1, tr_acc5 = eval_loss_acc1_acc5(model, train_loader4eval, loss_func, cuda)\n",
        "                print(\n",
        "                    '###Training loss:{:.4e}, top-1 accuracy:{:.5f}, top-5 accuracy:{:.5f}'.format(tr_loss, tr_acc1,\n",
        "                                                                                                   tr_acc5))\n",
        "\n",
        "                print(\n",
        "                    '***Validation loss:{:.4e}, top-1 accuracy:{:.5f}, top-5 accuracy:{:.5f}, current normalized energy:{:.4e}, {:.4e}(relaxed), sparsity: {:.4e}'.format(\n",
        "                        val_loss, val_acc1,\n",
        "                        val_acc5, cur_energy / budget_ub, cur_energy_relaxed / budget_ub, cur_sparsity))\n",
        "                # save current model\n",
        "                model_snapshot(model, os.path.join(logdir, 'primal_model_latest.pkl'))\n",
        "\n",
        "            if save_interval > 0 and epoch % save_interval == 0:\n",
        "                model_snapshot(model, os.path.join(logdir, 'Xprimal_model_epoch{}_{}.pkl'.format(iter_idx, epoch)))\n",
        "\n",
        "            elapse_time = time.time() - t_begin\n",
        "            speed_epoch = elapse_time / (1 + epoch)\n",
        "            eta = speed_epoch * (epochs - epoch)\n",
        "            print(\"Updating input mask, Elapsed {:.2f}s, ets {:.2f}s\".format(elapse_time, eta))\n",
        "\n",
        "        round_model_weights(model, param_name='input_mask')\n",
        "        # refresh X_energy_cache\n",
        "        reset_Xenergy_cache(energy_info)\n",
        "        cur_energy = energy_estimator(model)\n",
        "        cur_energy_relaxed = energy_estimator_relaxed(model)\n",
        "\n",
        "        iter_idx += 1\n",
        "        Xbudget -= 0.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Continue to train input mask.\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2599e+02, xlr=1.0000e-04, time_elapsed=0.390s\n",
            "sparsity:1.0\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=9.9990e-01, mean=9.9995e-01, max=1.0000e+00, nnz=1.0000\n",
            "          features.3abs(W): min=9.9990e-01, mean=9.9995e-01, max=1.0000e+00, nnz=1.0000\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2957e+02, xlr=1.0000e-04, time_elapsed=1.254s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.3005e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.7073e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2095e+02, xlr=1.0000e-04, time_elapsed=1.238s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.2842e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.6900e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 300/938 ----------------+\n",
            "primal update: net loss=1.2044e+02, xlr=1.0000e-04, time_elapsed=1.189s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.2679e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.6733e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3328e+02, xlr=1.0000e-04, time_elapsed=1.254s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.2517e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.6566e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 500/938 ----------------+\n",
            "primal update: net loss=1.1983e+02, xlr=1.0000e-04, time_elapsed=1.213s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.2351e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.6393e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 600/938 ----------------+\n",
            "primal update: net loss=1.2150e+02, xlr=1.0000e-04, time_elapsed=1.245s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.2188e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.6222e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 700/938 ----------------+\n",
            "primal update: net loss=1.4190e+02, xlr=1.0000e-04, time_elapsed=1.226s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.2027e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.6053e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 800/938 ----------------+\n",
            "primal update: net loss=1.3213e+02, xlr=1.0000e-04, time_elapsed=1.203s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.1864e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.5882e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 0, batch 900/938 ----------------+\n",
            "primal update: net loss=1.3638e+02, xlr=1.0000e-04, time_elapsed=1.187s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.1703e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.5715e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2846e+02, top-1 accuracy:0.10007, top-5 accuracy:0.51318\n",
            "***Validation loss:1.2961e+02, top-1 accuracy:0.09430, top-5 accuracy:0.51710, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 25.09s, ets 752.65s\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 0/938 ----------------+\n",
            "primal update: net loss=1.3322e+02, xlr=1.0000e-04, time_elapsed=14.049s\n",
            "sparsity:0.9190909090909091\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.1643e-01, max=1.0000e+00, nnz=0.9463\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.5652e-01, max=1.0000e+00, nnz=0.8954\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2180e+02, xlr=1.0000e-04, time_elapsed=1.249s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.1484e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.5486e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 200/938 ----------------+\n",
            "primal update: net loss=1.3126e+02, xlr=1.0000e-04, time_elapsed=1.215s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.1324e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.5317e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 300/938 ----------------+\n",
            "primal update: net loss=1.3633e+02, xlr=1.0000e-04, time_elapsed=1.224s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.1167e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.5151e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 400/938 ----------------+\n",
            "primal update: net loss=1.2116e+02, xlr=1.0000e-04, time_elapsed=1.221s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.1012e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.4983e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 500/938 ----------------+\n",
            "primal update: net loss=1.3139e+02, xlr=1.0000e-04, time_elapsed=1.264s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.0857e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.4817e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 600/938 ----------------+\n",
            "primal update: net loss=1.3956e+02, xlr=1.0000e-04, time_elapsed=1.191s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.0703e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.4651e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 700/938 ----------------+\n",
            "primal update: net loss=1.2701e+02, xlr=1.0000e-04, time_elapsed=1.190s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.0542e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.4479e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 800/938 ----------------+\n",
            "primal update: net loss=1.2657e+02, xlr=1.0000e-04, time_elapsed=1.216s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.0386e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.4313e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 1, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2253e+02, xlr=1.0000e-04, time_elapsed=1.213s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.0233e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.4147e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2844e+02, top-1 accuracy:0.11128, top-5 accuracy:0.51422\n",
            "***Validation loss:1.2960e+02, top-1 accuracy:0.10510, top-5 accuracy:0.51780, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 49.97s, ets 724.54s\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2690e+02, xlr=1.0000e-04, time_elapsed=13.895s\n",
            "sparsity:0.9222727272727272\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.0175e-01, max=1.0000e+00, nnz=0.9512\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.4082e-01, max=1.0000e+00, nnz=0.8971\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 100/938 ----------------+\n",
            "primal update: net loss=1.3041e+02, xlr=1.0000e-04, time_elapsed=1.300s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=9.0023e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.3914e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 200/938 ----------------+\n",
            "primal update: net loss=1.4474e+02, xlr=1.0000e-04, time_elapsed=1.243s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.9872e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.3749e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 300/938 ----------------+\n",
            "primal update: net loss=1.1941e+02, xlr=1.0000e-04, time_elapsed=1.237s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.9720e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.3583e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 400/938 ----------------+\n",
            "primal update: net loss=1.2608e+02, xlr=1.0000e-04, time_elapsed=1.249s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.9567e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.3409e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 500/938 ----------------+\n",
            "primal update: net loss=1.1754e+02, xlr=1.0000e-04, time_elapsed=1.290s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.9421e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.3245e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 600/938 ----------------+\n",
            "primal update: net loss=1.2450e+02, xlr=1.0000e-04, time_elapsed=1.262s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.9267e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.3074e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 700/938 ----------------+\n",
            "primal update: net loss=1.3541e+02, xlr=1.0000e-04, time_elapsed=1.233s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.9115e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.2908e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 800/938 ----------------+\n",
            "primal update: net loss=1.2077e+02, xlr=1.0000e-04, time_elapsed=1.265s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.8962e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.2739e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 2, batch 900/938 ----------------+\n",
            "primal update: net loss=1.3325e+02, xlr=1.0000e-04, time_elapsed=1.313s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.8812e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.2573e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2843e+02, top-1 accuracy:0.12063, top-5 accuracy:0.51582\n",
            "***Validation loss:1.2959e+02, top-1 accuracy:0.11600, top-5 accuracy:0.51910, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 75.23s, ets 702.11s\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2718e+02, xlr=1.0000e-04, time_elapsed=13.847s\n",
            "sparsity:0.9227272727272727\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.8756e-01, max=1.0000e+00, nnz=0.9473\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.2510e-01, max=1.0000e+00, nnz=0.9014\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2355e+02, xlr=1.0000e-04, time_elapsed=1.263s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.8609e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.2342e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 200/938 ----------------+\n",
            "primal update: net loss=1.3686e+02, xlr=1.0000e-04, time_elapsed=1.272s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.8458e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.2173e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 300/938 ----------------+\n",
            "primal update: net loss=1.2127e+02, xlr=1.0000e-04, time_elapsed=1.223s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.8307e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.2008e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 400/938 ----------------+\n",
            "primal update: net loss=1.4043e+02, xlr=1.0000e-04, time_elapsed=1.219s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.8158e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.1841e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 500/938 ----------------+\n",
            "primal update: net loss=1.2209e+02, xlr=1.0000e-04, time_elapsed=1.228s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.8005e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.1670e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 600/938 ----------------+\n",
            "primal update: net loss=1.2668e+02, xlr=1.0000e-04, time_elapsed=1.283s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.7862e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.1503e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 700/938 ----------------+\n",
            "primal update: net loss=1.3274e+02, xlr=1.0000e-04, time_elapsed=1.252s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.7713e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.1339e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 800/938 ----------------+\n",
            "primal update: net loss=1.1801e+02, xlr=1.0000e-04, time_elapsed=1.232s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.7567e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.1171e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 3, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2946e+02, xlr=1.0000e-04, time_elapsed=1.201s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.7420e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.1002e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2843e+02, top-1 accuracy:0.12958, top-5 accuracy:0.51755\n",
            "***Validation loss:1.2959e+02, top-1 accuracy:0.12590, top-5 accuracy:0.52070, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 100.26s, ets 676.73s\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2293e+02, xlr=1.0000e-04, time_elapsed=13.878s\n",
            "sparsity:0.9218181818181819\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.7365e-01, max=1.0000e+00, nnz=0.9463\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.0940e-01, max=1.0000e+00, nnz=0.9005\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 100/938 ----------------+\n",
            "primal update: net loss=1.3381e+02, xlr=1.0000e-04, time_elapsed=1.251s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.7217e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.0777e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 200/938 ----------------+\n",
            "primal update: net loss=1.1513e+02, xlr=1.0000e-04, time_elapsed=1.233s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.7070e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.0604e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 300/938 ----------------+\n",
            "primal update: net loss=1.4107e+02, xlr=1.0000e-04, time_elapsed=1.200s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.6924e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.0438e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3377e+02, xlr=1.0000e-04, time_elapsed=1.244s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.6778e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.0272e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 500/938 ----------------+\n",
            "primal update: net loss=1.1417e+02, xlr=1.0000e-04, time_elapsed=1.196s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.6629e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=8.0104e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 600/938 ----------------+\n",
            "primal update: net loss=1.1761e+02, xlr=1.0000e-04, time_elapsed=1.276s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.6480e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.9935e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 700/938 ----------------+\n",
            "primal update: net loss=1.4674e+02, xlr=1.0000e-04, time_elapsed=1.242s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.6333e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.9766e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 800/938 ----------------+\n",
            "primal update: net loss=1.4096e+02, xlr=1.0000e-04, time_elapsed=1.232s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.6186e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.9598e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 4, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2804e+02, xlr=1.0000e-04, time_elapsed=1.274s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.6037e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.9427e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2843e+02, top-1 accuracy:0.13863, top-5 accuracy:0.52035\n",
            "***Validation loss:1.2958e+02, top-1 accuracy:0.13390, top-5 accuracy:0.52470, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 125.75s, ets 653.88s\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2733e+02, xlr=1.0000e-04, time_elapsed=14.359s\n",
            "sparsity:0.9213636363636364\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.5982e-01, max=1.0000e+00, nnz=0.9453\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.9362e-01, max=1.0000e+00, nnz=0.9005\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 100/938 ----------------+\n",
            "primal update: net loss=1.1910e+02, xlr=1.0000e-04, time_elapsed=1.253s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.5838e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.9193e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 200/938 ----------------+\n",
            "primal update: net loss=1.3875e+02, xlr=1.0000e-04, time_elapsed=1.198s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.5687e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.9016e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 300/938 ----------------+\n",
            "primal update: net loss=1.3926e+02, xlr=1.0000e-04, time_elapsed=1.211s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.5537e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.8847e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3313e+02, xlr=1.0000e-04, time_elapsed=1.185s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.5393e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.8678e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 500/938 ----------------+\n",
            "primal update: net loss=1.2299e+02, xlr=1.0000e-04, time_elapsed=1.237s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.5251e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.8513e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 600/938 ----------------+\n",
            "primal update: net loss=1.3039e+02, xlr=1.0000e-04, time_elapsed=1.220s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.5106e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.8347e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 700/938 ----------------+\n",
            "primal update: net loss=1.2491e+02, xlr=1.0000e-04, time_elapsed=1.245s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.4963e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.8177e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 800/938 ----------------+\n",
            "primal update: net loss=1.1909e+02, xlr=1.0000e-04, time_elapsed=1.219s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.4819e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.8008e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 5, batch 900/938 ----------------+\n",
            "primal update: net loss=1.3061e+02, xlr=1.0000e-04, time_elapsed=1.225s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.4678e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.7840e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2841e+02, top-1 accuracy:0.14750, top-5 accuracy:0.52347\n",
            "***Validation loss:1.2957e+02, top-1 accuracy:0.14370, top-5 accuracy:0.52680, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 150.86s, ets 628.58s\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2341e+02, xlr=1.0000e-04, time_elapsed=14.084s\n",
            "sparsity:0.9231818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.4624e-01, max=1.0000e+00, nnz=0.9463\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.7777e-01, max=1.0000e+00, nnz=0.9031\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 100/938 ----------------+\n",
            "primal update: net loss=1.3447e+02, xlr=1.0000e-04, time_elapsed=1.255s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.4479e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.7608e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2460e+02, xlr=1.0000e-04, time_elapsed=1.253s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.4336e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.7438e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 300/938 ----------------+\n",
            "primal update: net loss=1.2121e+02, xlr=1.0000e-04, time_elapsed=1.245s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.4193e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.7267e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 400/938 ----------------+\n",
            "primal update: net loss=1.2729e+02, xlr=1.0000e-04, time_elapsed=1.231s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.4049e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.7096e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 500/938 ----------------+\n",
            "primal update: net loss=1.3493e+02, xlr=1.0000e-04, time_elapsed=1.226s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.3909e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.6927e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 600/938 ----------------+\n",
            "primal update: net loss=1.3771e+02, xlr=1.0000e-04, time_elapsed=1.196s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.3772e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.6764e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 700/938 ----------------+\n",
            "primal update: net loss=1.3100e+02, xlr=1.0000e-04, time_elapsed=1.187s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.3631e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.6598e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 800/938 ----------------+\n",
            "primal update: net loss=1.2128e+02, xlr=1.0000e-04, time_elapsed=1.209s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.3491e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.6428e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 6, batch 900/938 ----------------+\n",
            "primal update: net loss=1.3855e+02, xlr=1.0000e-04, time_elapsed=1.205s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.3349e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.6260e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2841e+02, top-1 accuracy:0.15515, top-5 accuracy:0.52752\n",
            "***Validation loss:1.2956e+02, top-1 accuracy:0.15150, top-5 accuracy:0.53030, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 176.05s, ets 603.60s\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 0/938 ----------------+\n",
            "primal update: net loss=1.3801e+02, xlr=1.0000e-04, time_elapsed=14.216s\n",
            "sparsity:0.9231818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.3295e-01, max=1.0000e+00, nnz=0.9482\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.6194e-01, max=1.0000e+00, nnz=0.9014\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2589e+02, xlr=1.0000e-04, time_elapsed=1.244s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.3151e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.6028e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2201e+02, xlr=1.0000e-04, time_elapsed=1.215s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.3008e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.5853e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 300/938 ----------------+\n",
            "primal update: net loss=1.1793e+02, xlr=1.0000e-04, time_elapsed=1.236s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.2865e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.5683e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3082e+02, xlr=1.0000e-04, time_elapsed=1.258s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.2723e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.5519e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 500/938 ----------------+\n",
            "primal update: net loss=1.2639e+02, xlr=1.0000e-04, time_elapsed=1.237s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.2582e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.5353e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 600/938 ----------------+\n",
            "primal update: net loss=1.3644e+02, xlr=1.0000e-04, time_elapsed=1.226s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.2440e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.5184e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 700/938 ----------------+\n",
            "primal update: net loss=1.3067e+02, xlr=1.0000e-04, time_elapsed=1.252s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.2300e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.5015e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 800/938 ----------------+\n",
            "primal update: net loss=1.3226e+02, xlr=1.0000e-04, time_elapsed=1.258s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.2160e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.4848e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 7, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2780e+02, xlr=1.0000e-04, time_elapsed=1.268s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.2022e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.4681e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2840e+02, top-1 accuracy:0.16220, top-5 accuracy:0.53132\n",
            "***Validation loss:1.2955e+02, top-1 accuracy:0.15940, top-5 accuracy:0.53510, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 201.40s, ets 579.01s\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2967e+02, xlr=1.0000e-04, time_elapsed=14.111s\n",
            "sparsity:0.9231818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.1969e-01, max=1.0000e+00, nnz=0.9502\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.4618e-01, max=1.0000e+00, nnz=0.8997\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 100/938 ----------------+\n",
            "primal update: net loss=1.1911e+02, xlr=1.0000e-04, time_elapsed=1.341s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.1829e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.4452e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 200/938 ----------------+\n",
            "primal update: net loss=1.3106e+02, xlr=1.0000e-04, time_elapsed=1.238s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.1690e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.4285e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 300/938 ----------------+\n",
            "primal update: net loss=1.2415e+02, xlr=1.0000e-04, time_elapsed=1.243s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.1548e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.4117e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3017e+02, xlr=1.0000e-04, time_elapsed=1.254s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.1404e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.3942e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 500/938 ----------------+\n",
            "primal update: net loss=1.3545e+02, xlr=1.0000e-04, time_elapsed=1.275s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.1266e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.3781e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 600/938 ----------------+\n",
            "primal update: net loss=1.3317e+02, xlr=1.0000e-04, time_elapsed=1.226s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.1127e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.3613e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 700/938 ----------------+\n",
            "primal update: net loss=1.4563e+02, xlr=1.0000e-04, time_elapsed=1.265s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.0988e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.3446e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 800/938 ----------------+\n",
            "primal update: net loss=1.3476e+02, xlr=1.0000e-04, time_elapsed=1.281s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.0847e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.3278e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 8, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2062e+02, xlr=1.0000e-04, time_elapsed=1.240s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.0705e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.3107e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2838e+02, top-1 accuracy:0.16942, top-5 accuracy:0.53517\n",
            "***Validation loss:1.2954e+02, top-1 accuracy:0.16580, top-5 accuracy:0.54040, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 226.88s, ets 554.60s\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2075e+02, xlr=1.0000e-04, time_elapsed=14.123s\n",
            "sparsity:0.9245454545454546\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.0653e-01, max=1.0000e+00, nnz=0.9492\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.3044e-01, max=1.0000e+00, nnz=0.9031\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2212e+02, xlr=1.0000e-04, time_elapsed=1.273s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.0513e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.2876e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 200/938 ----------------+\n",
            "primal update: net loss=1.1708e+02, xlr=1.0000e-04, time_elapsed=1.215s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.0373e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.2707e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 300/938 ----------------+\n",
            "primal update: net loss=1.2405e+02, xlr=1.0000e-04, time_elapsed=1.243s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.0234e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.2540e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 400/938 ----------------+\n",
            "primal update: net loss=1.2285e+02, xlr=1.0000e-04, time_elapsed=1.231s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=8.0093e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.2372e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 500/938 ----------------+\n",
            "primal update: net loss=1.0986e+02, xlr=1.0000e-04, time_elapsed=1.224s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.9955e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.2208e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 600/938 ----------------+\n",
            "primal update: net loss=1.2772e+02, xlr=1.0000e-04, time_elapsed=1.265s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.9814e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.2039e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 700/938 ----------------+\n",
            "primal update: net loss=1.2284e+02, xlr=1.0000e-04, time_elapsed=1.269s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.9677e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.1873e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 800/938 ----------------+\n",
            "primal update: net loss=1.2644e+02, xlr=1.0000e-04, time_elapsed=1.238s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.9535e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.1704e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 9, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2782e+02, xlr=1.0000e-04, time_elapsed=1.245s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.9396e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.1538e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2839e+02, top-1 accuracy:0.17598, top-5 accuracy:0.53890\n",
            "***Validation loss:1.2954e+02, top-1 accuracy:0.17240, top-5 accuracy:0.54490, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 252.04s, ets 529.28s\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 0/938 ----------------+\n",
            "primal update: net loss=1.1797e+02, xlr=1.0000e-04, time_elapsed=13.978s\n",
            "sparsity:0.9231818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.9343e-01, max=1.0000e+00, nnz=0.9502\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.1472e-01, max=1.0000e+00, nnz=0.8997\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 100/938 ----------------+\n",
            "primal update: net loss=1.3335e+02, xlr=1.0000e-04, time_elapsed=1.220s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.9207e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.1305e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2797e+02, xlr=1.0000e-04, time_elapsed=1.216s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.9072e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.1140e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 300/938 ----------------+\n",
            "primal update: net loss=1.3412e+02, xlr=1.0000e-04, time_elapsed=1.211s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.8934e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.0972e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3190e+02, xlr=1.0000e-04, time_elapsed=1.246s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.8797e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.0801e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 500/938 ----------------+\n",
            "primal update: net loss=1.3799e+02, xlr=1.0000e-04, time_elapsed=1.243s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.8659e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.0637e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 600/938 ----------------+\n",
            "primal update: net loss=1.2993e+02, xlr=1.0000e-04, time_elapsed=1.221s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.8521e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.0470e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 700/938 ----------------+\n",
            "primal update: net loss=1.2627e+02, xlr=1.0000e-04, time_elapsed=1.225s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.8386e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.0304e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 800/938 ----------------+\n",
            "primal update: net loss=1.1248e+02, xlr=1.0000e-04, time_elapsed=1.289s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.8250e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=7.0134e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 10, batch 900/938 ----------------+\n",
            "primal update: net loss=1.0942e+02, xlr=1.0000e-04, time_elapsed=1.207s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.8112e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.9963e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2838e+02, top-1 accuracy:0.18133, top-5 accuracy:0.54200\n",
            "***Validation loss:1.2953e+02, top-1 accuracy:0.17820, top-5 accuracy:0.54760, current normalized energy:9.8888e-01, 9.9422e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 277.10s, ets 503.83s\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 0/938 ----------------+\n",
            "primal update: net loss=1.3474e+02, xlr=1.0000e-04, time_elapsed=13.922s\n",
            "sparsity:0.9209090909090909\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.8060e-01, max=1.0000e+00, nnz=0.9434\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.9898e-01, max=1.0000e+00, nnz=0.9014\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 100/938 ----------------+\n",
            "primal update: net loss=1.3132e+02, xlr=1.0000e-04, time_elapsed=1.254s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.7923e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.9730e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 200/938 ----------------+\n",
            "primal update: net loss=1.4124e+02, xlr=1.0000e-04, time_elapsed=1.200s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.7789e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.9561e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 300/938 ----------------+\n",
            "primal update: net loss=1.1951e+02, xlr=1.0000e-04, time_elapsed=1.192s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.7653e-01, max=1.0000e+00, nnz=0.9316\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.9394e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 400/938 ----------------+\n",
            "primal update: net loss=1.2056e+02, xlr=1.0000e-04, time_elapsed=1.215s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.7518e-01, max=1.0000e+00, nnz=0.9307\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.9230e-01, max=1.0000e+00, nnz=0.8733\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 500/938 ----------------+\n",
            "primal update: net loss=1.2884e+02, xlr=1.0000e-04, time_elapsed=1.277s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.7381e-01, max=1.0000e+00, nnz=0.9307\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.9068e-01, max=1.0000e+00, nnz=0.8733\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 600/938 ----------------+\n",
            "primal update: net loss=1.2214e+02, xlr=1.0000e-04, time_elapsed=1.240s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.7244e-01, max=1.0000e+00, nnz=0.9307\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.8901e-01, max=1.0000e+00, nnz=0.8733\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 700/938 ----------------+\n",
            "primal update: net loss=1.2290e+02, xlr=1.0000e-04, time_elapsed=1.203s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.7110e-01, max=1.0000e+00, nnz=0.9307\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.8734e-01, max=1.0000e+00, nnz=0.8733\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 800/938 ----------------+\n",
            "primal update: net loss=1.2238e+02, xlr=1.0000e-04, time_elapsed=1.315s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.6973e-01, max=1.0000e+00, nnz=0.9307\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.8566e-01, max=1.0000e+00, nnz=0.8733\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 11, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2989e+02, xlr=1.0000e-04, time_elapsed=1.272s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.6841e-01, max=1.0000e+00, nnz=0.9307\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.8402e-01, max=1.0000e+00, nnz=0.8733\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2836e+02, top-1 accuracy:0.18653, top-5 accuracy:0.54545\n",
            "***Validation loss:1.2952e+02, top-1 accuracy:0.18370, top-5 accuracy:0.55020, current normalized energy:9.8874e-01, 9.9417e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 302.60s, ets 479.12s\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 0/938 ----------------+\n",
            "primal update: net loss=1.1703e+02, xlr=1.0000e-04, time_elapsed=14.388s\n",
            "sparsity:0.9181818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.6791e-01, max=1.0000e+00, nnz=0.9404\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.8339e-01, max=1.0000e+00, nnz=0.8988\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2685e+02, xlr=1.0000e-04, time_elapsed=1.255s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.6659e-01, max=1.0000e+00, nnz=0.9297\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.8179e-01, max=1.0000e+00, nnz=0.8741\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2750e+02, xlr=1.0000e-04, time_elapsed=1.258s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.6527e-01, max=1.0000e+00, nnz=0.9277\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.8022e-01, max=1.0000e+00, nnz=0.8759\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 300/938 ----------------+\n",
            "primal update: net loss=1.3746e+02, xlr=1.0000e-04, time_elapsed=1.209s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.6392e-01, max=1.0000e+00, nnz=0.9277\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.7865e-01, max=1.0000e+00, nnz=0.8759\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3125e+02, xlr=1.0000e-04, time_elapsed=1.216s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.6261e-01, max=1.0000e+00, nnz=0.9277\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.7713e-01, max=1.0000e+00, nnz=0.8759\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 500/938 ----------------+\n",
            "primal update: net loss=1.3090e+02, xlr=1.0000e-04, time_elapsed=1.197s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.6132e-01, max=1.0000e+00, nnz=0.9277\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.7559e-01, max=1.0000e+00, nnz=0.8759\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 600/938 ----------------+\n",
            "primal update: net loss=1.2336e+02, xlr=1.0000e-04, time_elapsed=1.234s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.6001e-01, max=1.0000e+00, nnz=0.9258\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.7410e-01, max=1.0000e+00, nnz=0.8776\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 700/938 ----------------+\n",
            "primal update: net loss=1.2104e+02, xlr=1.0000e-04, time_elapsed=1.226s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.5871e-01, max=1.0000e+00, nnz=0.9248\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.7264e-01, max=1.0000e+00, nnz=0.8784\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 800/938 ----------------+\n",
            "primal update: net loss=1.2883e+02, xlr=1.0000e-04, time_elapsed=1.219s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.5745e-01, max=1.0000e+00, nnz=0.9238\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.7118e-01, max=1.0000e+00, nnz=0.8793\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 12, batch 900/938 ----------------+\n",
            "primal update: net loss=1.1267e+02, xlr=1.0000e-04, time_elapsed=1.241s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.5622e-01, max=1.0000e+00, nnz=0.9229\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.6977e-01, max=1.0000e+00, nnz=0.8801\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2835e+02, top-1 accuracy:0.19108, top-5 accuracy:0.54705\n",
            "***Validation loss:1.2951e+02, top-1 accuracy:0.18820, top-5 accuracy:0.55280, current normalized energy:9.8854e-01, 9.9409e-01(relaxed), sparsity: 9.0000e-01\n",
            "Updating input mask, Elapsed 327.67s, ets 453.70s\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2377e+02, xlr=1.0000e-04, time_elapsed=13.963s\n",
            "sparsity:0.9086363636363637\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.5579e-01, max=1.0000e+00, nnz=0.9297\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.6924e-01, max=1.0000e+00, nnz=0.8903\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 100/938 ----------------+\n",
            "primal update: net loss=1.1384e+02, xlr=1.0000e-04, time_elapsed=1.305s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.5457e-01, max=1.0000e+00, nnz=0.9229\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.6778e-01, max=1.0000e+00, nnz=0.8801\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 200/938 ----------------+\n",
            "primal update: net loss=1.3552e+02, xlr=1.0000e-04, time_elapsed=1.225s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.5338e-01, max=1.0000e+00, nnz=0.9238\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.6637e-01, max=1.0000e+00, nnz=0.8793\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 300/938 ----------------+\n",
            "primal update: net loss=1.2264e+02, xlr=1.0000e-04, time_elapsed=1.304s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.5220e-01, max=1.0000e+00, nnz=0.9238\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.6498e-01, max=1.0000e+00, nnz=0.8793\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 400/938 ----------------+\n",
            "primal update: net loss=1.2262e+02, xlr=1.0000e-04, time_elapsed=1.231s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.5105e-01, max=1.0000e+00, nnz=0.9229\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.6361e-01, max=1.0000e+00, nnz=0.8801\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 500/938 ----------------+\n",
            "primal update: net loss=1.3643e+02, xlr=1.0000e-04, time_elapsed=1.230s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4991e-01, max=1.0000e+00, nnz=0.9248\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.6220e-01, max=1.0000e+00, nnz=0.8784\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 600/938 ----------------+\n",
            "primal update: net loss=1.3699e+02, xlr=1.0000e-04, time_elapsed=1.284s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4873e-01, max=1.0000e+00, nnz=0.9219\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.6084e-01, max=1.0000e+00, nnz=0.8810\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 700/938 ----------------+\n",
            "primal update: net loss=1.3068e+02, xlr=1.0000e-04, time_elapsed=1.207s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4754e-01, max=1.0000e+00, nnz=0.9229\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.5949e-01, max=1.0000e+00, nnz=0.8801\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 800/938 ----------------+\n",
            "primal update: net loss=1.2461e+02, xlr=1.0000e-04, time_elapsed=1.217s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4640e-01, max=1.0000e+00, nnz=0.9248\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.5817e-01, max=1.0000e+00, nnz=0.8784\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 13, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2478e+02, xlr=1.0000e-04, time_elapsed=1.241s\n",
            "sparsity:0.8954545454545455\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4525e-01, max=1.0000e+00, nnz=0.9209\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.5683e-01, max=1.0000e+00, nnz=0.8733\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2835e+02, top-1 accuracy:0.19407, top-5 accuracy:0.54758\n",
            "***Validation loss:1.2950e+02, top-1 accuracy:0.19060, top-5 accuracy:0.55440, current normalized energy:9.8756e-01, 9.9371e-01(relaxed), sparsity: 8.9909e-01\n",
            "Updating input mask, Elapsed 352.95s, ets 428.59s\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 0/938 ----------------+\n",
            "primal update: net loss=1.3331e+02, xlr=1.0000e-04, time_elapsed=14.068s\n",
            "sparsity:0.9\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4482e-01, max=1.0000e+00, nnz=0.9229\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.5634e-01, max=1.0000e+00, nnz=0.8801\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2918e+02, xlr=1.0000e-04, time_elapsed=1.269s\n",
            "sparsity:0.899090909090909\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4373e-01, max=1.0000e+00, nnz=0.9229\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.5509e-01, max=1.0000e+00, nnz=0.8784\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2188e+02, xlr=1.0000e-04, time_elapsed=1.261s\n",
            "sparsity:0.8968181818181818\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4261e-01, max=1.0000e+00, nnz=0.9229\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.5380e-01, max=1.0000e+00, nnz=0.8741\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 300/938 ----------------+\n",
            "primal update: net loss=1.3223e+02, xlr=1.0000e-04, time_elapsed=1.226s\n",
            "sparsity:0.8945454545454545\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4149e-01, max=1.0000e+00, nnz=0.9199\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.5254e-01, max=1.0000e+00, nnz=0.8724\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 400/938 ----------------+\n",
            "primal update: net loss=1.2171e+02, xlr=1.0000e-04, time_elapsed=1.260s\n",
            "sparsity:0.8931818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.4038e-01, max=1.0000e+00, nnz=0.9180\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.5129e-01, max=1.0000e+00, nnz=0.8716\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 500/938 ----------------+\n",
            "primal update: net loss=1.2655e+02, xlr=1.0000e-04, time_elapsed=1.238s\n",
            "sparsity:0.8918181818181818\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3928e-01, max=1.0000e+00, nnz=0.9150\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.5005e-01, max=1.0000e+00, nnz=0.8716\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 600/938 ----------------+\n",
            "primal update: net loss=1.3188e+02, xlr=1.0000e-04, time_elapsed=1.282s\n",
            "sparsity:0.8886363636363637\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3819e-01, max=1.0000e+00, nnz=0.9150\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.4886e-01, max=1.0000e+00, nnz=0.8656\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 700/938 ----------------+\n",
            "primal update: net loss=1.3577e+02, xlr=1.0000e-04, time_elapsed=1.261s\n",
            "sparsity:0.8868181818181818\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3711e-01, max=1.0000e+00, nnz=0.9111\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.4766e-01, max=1.0000e+00, nnz=0.8656\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 800/938 ----------------+\n",
            "primal update: net loss=1.3553e+02, xlr=1.0000e-04, time_elapsed=1.237s\n",
            "sparsity:0.8868181818181818\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3608e-01, max=1.0000e+00, nnz=0.9102\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.4646e-01, max=1.0000e+00, nnz=0.8665\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 14, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2782e+02, xlr=1.0000e-04, time_elapsed=1.271s\n",
            "sparsity:0.8845454545454545\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3507e-01, max=1.0000e+00, nnz=0.9092\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.4528e-01, max=1.0000e+00, nnz=0.8631\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2834e+02, top-1 accuracy:0.19635, top-5 accuracy:0.54760\n",
            "***Validation loss:1.2949e+02, top-1 accuracy:0.19300, top-5 accuracy:0.55370, current normalized energy:9.8563e-01, 9.9273e-01(relaxed), sparsity: 8.8364e-01\n",
            "Updating input mask, Elapsed 378.40s, ets 403.63s\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 0/938 ----------------+\n",
            "primal update: net loss=1.0723e+02, xlr=1.0000e-04, time_elapsed=14.101s\n",
            "sparsity:0.8831818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3468e-01, max=1.0000e+00, nnz=0.9072\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.4484e-01, max=1.0000e+00, nnz=0.8622\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 100/938 ----------------+\n",
            "primal update: net loss=1.3031e+02, xlr=1.0000e-04, time_elapsed=1.300s\n",
            "sparsity:0.8790909090909091\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3370e-01, max=1.0000e+00, nnz=0.9043\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.4368e-01, max=1.0000e+00, nnz=0.8571\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2117e+02, xlr=1.0000e-04, time_elapsed=1.219s\n",
            "sparsity:0.8795454545454545\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3274e-01, max=1.0000e+00, nnz=0.9043\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.4256e-01, max=1.0000e+00, nnz=0.8580\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 300/938 ----------------+\n",
            "primal update: net loss=1.2303e+02, xlr=1.0000e-04, time_elapsed=1.321s\n",
            "sparsity:0.8781818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3176e-01, max=1.0000e+00, nnz=0.9043\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.4143e-01, max=1.0000e+00, nnz=0.8554\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 400/938 ----------------+\n",
            "primal update: net loss=1.2667e+02, xlr=1.0000e-04, time_elapsed=1.317s\n",
            "sparsity:0.8781818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.3079e-01, max=1.0000e+00, nnz=0.9043\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.4032e-01, max=1.0000e+00, nnz=0.8554\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 500/938 ----------------+\n",
            "primal update: net loss=1.1151e+02, xlr=1.0000e-04, time_elapsed=1.225s\n",
            "sparsity:0.875\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2982e-01, max=1.0000e+00, nnz=0.9033\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3920e-01, max=1.0000e+00, nnz=0.8503\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 600/938 ----------------+\n",
            "primal update: net loss=1.4206e+02, xlr=1.0000e-04, time_elapsed=1.242s\n",
            "sparsity:0.8740909090909091\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2886e-01, max=1.0000e+00, nnz=0.9033\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3809e-01, max=1.0000e+00, nnz=0.8486\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 700/938 ----------------+\n",
            "primal update: net loss=1.2943e+02, xlr=1.0000e-04, time_elapsed=1.248s\n",
            "sparsity:0.8727272727272727\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2795e-01, max=1.0000e+00, nnz=0.8975\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3705e-01, max=1.0000e+00, nnz=0.8512\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 800/938 ----------------+\n",
            "primal update: net loss=1.3050e+02, xlr=1.0000e-04, time_elapsed=1.220s\n",
            "sparsity:0.8686363636363637\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2708e-01, max=1.0000e+00, nnz=0.8955\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3599e-01, max=1.0000e+00, nnz=0.8452\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 15, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2655e+02, xlr=1.0000e-04, time_elapsed=1.257s\n",
            "sparsity:0.8668181818181818\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2621e-01, max=1.0000e+00, nnz=0.8945\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3498e-01, max=1.0000e+00, nnz=0.8427\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2833e+02, top-1 accuracy:0.19777, top-5 accuracy:0.54777\n",
            "***Validation loss:1.2949e+02, top-1 accuracy:0.19440, top-5 accuracy:0.55300, current normalized energy:9.8340e-01, 9.9160e-01(relaxed), sparsity: 8.6500e-01\n",
            "Updating input mask, Elapsed 404.08s, ets 378.83s\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2344e+02, xlr=1.0000e-04, time_elapsed=14.365s\n",
            "sparsity:0.8663636363636363\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2588e-01, max=1.0000e+00, nnz=0.8955\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3459e-01, max=1.0000e+00, nnz=0.8410\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2597e+02, xlr=1.0000e-04, time_elapsed=1.291s\n",
            "sparsity:0.865909090909091\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2501e-01, max=1.0000e+00, nnz=0.8926\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3359e-01, max=1.0000e+00, nnz=0.8427\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2970e+02, xlr=1.0000e-04, time_elapsed=1.259s\n",
            "sparsity:0.8622727272727273\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2416e-01, max=1.0000e+00, nnz=0.8916\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3261e-01, max=1.0000e+00, nnz=0.8367\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 300/938 ----------------+\n",
            "primal update: net loss=1.3306e+02, xlr=1.0000e-04, time_elapsed=1.265s\n",
            "sparsity:0.8581818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2330e-01, max=1.0000e+00, nnz=0.8857\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3162e-01, max=1.0000e+00, nnz=0.8342\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3222e+02, xlr=1.0000e-04, time_elapsed=1.286s\n",
            "sparsity:0.8568181818181818\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2245e-01, max=1.0000e+00, nnz=0.8857\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.3066e-01, max=1.0000e+00, nnz=0.8316\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 500/938 ----------------+\n",
            "primal update: net loss=1.2181e+02, xlr=1.0000e-04, time_elapsed=1.263s\n",
            "sparsity:0.8554545454545455\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2161e-01, max=1.0000e+00, nnz=0.8877\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2973e-01, max=1.0000e+00, nnz=0.8274\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 600/938 ----------------+\n",
            "primal update: net loss=1.3380e+02, xlr=1.0000e-04, time_elapsed=1.277s\n",
            "sparsity:0.8536363636363636\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.2079e-01, max=1.0000e+00, nnz=0.8867\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2879e-01, max=1.0000e+00, nnz=0.8248\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 700/938 ----------------+\n",
            "primal update: net loss=1.2669e+02, xlr=1.0000e-04, time_elapsed=1.254s\n",
            "sparsity:0.8540909090909091\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1997e-01, max=1.0000e+00, nnz=0.8867\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2786e-01, max=1.0000e+00, nnz=0.8257\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 800/938 ----------------+\n",
            "primal update: net loss=1.1668e+02, xlr=1.0000e-04, time_elapsed=1.238s\n",
            "sparsity:0.8536363636363636\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1915e-01, max=1.0000e+00, nnz=0.8877\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2698e-01, max=1.0000e+00, nnz=0.8240\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 16, batch 900/938 ----------------+\n",
            "primal update: net loss=1.1293e+02, xlr=1.0000e-04, time_elapsed=1.267s\n",
            "sparsity:0.8513636363636363\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1832e-01, max=1.0000e+00, nnz=0.8838\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2609e-01, max=1.0000e+00, nnz=0.8231\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2833e+02, top-1 accuracy:0.19845, top-5 accuracy:0.54678\n",
            "***Validation loss:1.2948e+02, top-1 accuracy:0.19610, top-5 accuracy:0.55160, current normalized energy:9.8171e-01, 9.9074e-01(relaxed), sparsity: 8.5091e-01\n",
            "Updating input mask, Elapsed 429.73s, ets 353.89s\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 0/938 ----------------+\n",
            "primal update: net loss=1.1870e+02, xlr=1.0000e-04, time_elapsed=14.201s\n",
            "sparsity:0.8504545454545455\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1803e-01, max=1.0000e+00, nnz=0.8838\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2578e-01, max=1.0000e+00, nnz=0.8214\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2535e+02, xlr=1.0000e-04, time_elapsed=1.343s\n",
            "sparsity:0.8481818181818181\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1723e-01, max=1.0000e+00, nnz=0.8809\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2488e-01, max=1.0000e+00, nnz=0.8197\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 200/938 ----------------+\n",
            "primal update: net loss=1.1730e+02, xlr=1.0000e-04, time_elapsed=1.225s\n",
            "sparsity:0.8463636363636363\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1648e-01, max=1.0000e+00, nnz=0.8779\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2406e-01, max=1.0000e+00, nnz=0.8189\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 300/938 ----------------+\n",
            "primal update: net loss=1.2449e+02, xlr=1.0000e-04, time_elapsed=1.254s\n",
            "sparsity:0.8418181818181818\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1573e-01, max=1.0000e+00, nnz=0.8750\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2323e-01, max=1.0000e+00, nnz=0.8129\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3934e+02, xlr=1.0000e-04, time_elapsed=1.253s\n",
            "sparsity:0.8409090909090909\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1501e-01, max=1.0000e+00, nnz=0.8730\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2242e-01, max=1.0000e+00, nnz=0.8129\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 500/938 ----------------+\n",
            "primal update: net loss=1.3142e+02, xlr=1.0000e-04, time_elapsed=1.271s\n",
            "sparsity:0.8390909090909091\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1430e-01, max=1.0000e+00, nnz=0.8711\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2159e-01, max=1.0000e+00, nnz=0.8112\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 600/938 ----------------+\n",
            "primal update: net loss=1.2547e+02, xlr=1.0000e-04, time_elapsed=1.284s\n",
            "sparsity:0.8372727272727273\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1360e-01, max=1.0000e+00, nnz=0.8691\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2082e-01, max=1.0000e+00, nnz=0.8095\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 700/938 ----------------+\n",
            "primal update: net loss=1.3729e+02, xlr=1.0000e-04, time_elapsed=1.222s\n",
            "sparsity:0.8336363636363636\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1289e-01, max=1.0000e+00, nnz=0.8672\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.2001e-01, max=1.0000e+00, nnz=0.8044\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 800/938 ----------------+\n",
            "primal update: net loss=1.1418e+02, xlr=1.0000e-04, time_elapsed=1.212s\n",
            "sparsity:0.8309090909090909\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1222e-01, max=1.0000e+00, nnz=0.8633\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1923e-01, max=1.0000e+00, nnz=0.8027\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 17, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2090e+02, xlr=1.0000e-04, time_elapsed=1.219s\n",
            "sparsity:0.8318181818181818\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1156e-01, max=1.0000e+00, nnz=0.8633\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1850e-01, max=1.0000e+00, nnz=0.8044\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2832e+02, top-1 accuracy:0.19858, top-5 accuracy:0.54547\n",
            "***Validation loss:1.2948e+02, top-1 accuracy:0.19720, top-5 accuracy:0.55060, current normalized energy:9.7912e-01, 9.8942e-01(relaxed), sparsity: 8.3045e-01\n",
            "Updating input mask, Elapsed 455.15s, ets 328.72s\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 0/938 ----------------+\n",
            "primal update: net loss=1.4131e+02, xlr=1.0000e-04, time_elapsed=14.176s\n",
            "sparsity:0.83\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1132e-01, max=1.0000e+00, nnz=0.8604\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1820e-01, max=1.0000e+00, nnz=0.8036\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 100/938 ----------------+\n",
            "primal update: net loss=1.2262e+02, xlr=1.0000e-04, time_elapsed=1.275s\n",
            "sparsity:0.8277272727272728\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1068e-01, max=1.0000e+00, nnz=0.8594\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1745e-01, max=1.0000e+00, nnz=0.8002\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2885e+02, xlr=1.0000e-04, time_elapsed=1.256s\n",
            "sparsity:0.8263636363636364\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.1003e-01, max=1.0000e+00, nnz=0.8574\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1672e-01, max=1.0000e+00, nnz=0.7993\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 300/938 ----------------+\n",
            "primal update: net loss=1.1773e+02, xlr=1.0000e-04, time_elapsed=1.284s\n",
            "sparsity:0.8236363636363636\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0942e-01, max=1.0000e+00, nnz=0.8506\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1600e-01, max=1.0000e+00, nnz=0.8002\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 400/938 ----------------+\n",
            "primal update: net loss=1.2072e+02, xlr=1.0000e-04, time_elapsed=1.281s\n",
            "sparsity:0.8231818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0878e-01, max=1.0000e+00, nnz=0.8525\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1532e-01, max=1.0000e+00, nnz=0.7976\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 500/938 ----------------+\n",
            "primal update: net loss=1.2444e+02, xlr=1.0000e-04, time_elapsed=1.263s\n",
            "sparsity:0.8213636363636364\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0820e-01, max=1.0000e+00, nnz=0.8486\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1463e-01, max=1.0000e+00, nnz=0.7976\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 600/938 ----------------+\n",
            "primal update: net loss=1.3355e+02, xlr=1.0000e-04, time_elapsed=1.319s\n",
            "sparsity:0.8195454545454546\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0764e-01, max=1.0000e+00, nnz=0.8477\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1395e-01, max=1.0000e+00, nnz=0.7951\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 700/938 ----------------+\n",
            "primal update: net loss=1.2781e+02, xlr=1.0000e-04, time_elapsed=1.268s\n",
            "sparsity:0.8190909090909091\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0705e-01, max=1.0000e+00, nnz=0.8486\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1327e-01, max=1.0000e+00, nnz=0.7934\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 800/938 ----------------+\n",
            "primal update: net loss=1.3713e+02, xlr=1.0000e-04, time_elapsed=1.253s\n",
            "sparsity:0.8181818181818182\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0648e-01, max=1.0000e+00, nnz=0.8467\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1261e-01, max=1.0000e+00, nnz=0.7934\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 18, batch 900/938 ----------------+\n",
            "primal update: net loss=1.4380e+02, xlr=1.0000e-04, time_elapsed=1.263s\n",
            "sparsity:0.8168181818181818\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0588e-01, max=1.0000e+00, nnz=0.8467\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1194e-01, max=1.0000e+00, nnz=0.7908\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "###Training loss:1.2832e+02, top-1 accuracy:0.19850, top-5 accuracy:0.54477\n",
            "***Validation loss:1.2947e+02, top-1 accuracy:0.19800, top-5 accuracy:0.54880, current normalized energy:9.7766e-01, 9.8866e-01(relaxed), sparsity: 8.1727e-01\n",
            "Updating input mask, Elapsed 481.03s, ets 303.81s\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 0/938 ----------------+\n",
            "primal update: net loss=1.2481e+02, xlr=1.0000e-04, time_elapsed=14.361s\n",
            "sparsity:0.8172727272727273\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0567e-01, max=1.0000e+00, nnz=0.8457\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1169e-01, max=1.0000e+00, nnz=0.7925\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 100/938 ----------------+\n",
            "primal update: net loss=1.3119e+02, xlr=1.0000e-04, time_elapsed=1.281s\n",
            "sparsity:0.815\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0511e-01, max=1.0000e+00, nnz=0.8447\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1103e-01, max=1.0000e+00, nnz=0.7891\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 200/938 ----------------+\n",
            "primal update: net loss=1.2494e+02, xlr=1.0000e-04, time_elapsed=1.265s\n",
            "sparsity:0.8140909090909091\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0454e-01, max=1.0000e+00, nnz=0.8438\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.1038e-01, max=1.0000e+00, nnz=0.7883\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 300/938 ----------------+\n",
            "primal update: net loss=1.4121e+02, xlr=1.0000e-04, time_elapsed=1.245s\n",
            "sparsity:0.8145454545454546\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0399e-01, max=1.0000e+00, nnz=0.8428\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.0974e-01, max=1.0000e+00, nnz=0.7900\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 400/938 ----------------+\n",
            "primal update: net loss=1.3460e+02, xlr=1.0000e-04, time_elapsed=1.298s\n",
            "sparsity:0.8122727272727273\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0347e-01, max=1.0000e+00, nnz=0.8408\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.0913e-01, max=1.0000e+00, nnz=0.7874\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 500/938 ----------------+\n",
            "primal update: net loss=1.3821e+02, xlr=1.0000e-04, time_elapsed=1.277s\n",
            "sparsity:0.81\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0290e-01, max=1.0000e+00, nnz=0.8389\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.0852e-01, max=1.0000e+00, nnz=0.7849\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 600/938 ----------------+\n",
            "primal update: net loss=1.2786e+02, xlr=1.0000e-04, time_elapsed=1.287s\n",
            "sparsity:0.8086363636363636\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0236e-01, max=1.0000e+00, nnz=0.8389\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.0792e-01, max=1.0000e+00, nnz=0.7823\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 700/938 ----------------+\n",
            "primal update: net loss=1.3463e+02, xlr=1.0000e-04, time_elapsed=1.278s\n",
            "sparsity:0.8113636363636364\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0181e-01, max=1.0000e+00, nnz=0.8398\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.0731e-01, max=1.0000e+00, nnz=0.7866\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 800/938 ----------------+\n",
            "primal update: net loss=1.3223e+02, xlr=1.0000e-04, time_elapsed=1.262s\n",
            "sparsity:0.8072727272727273\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0125e-01, max=1.0000e+00, nnz=0.8359\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.0671e-01, max=1.0000e+00, nnz=0.7823\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n",
            "======================================================\n",
            "+-------------- epoch 19, batch 900/938 ----------------+\n",
            "primal update: net loss=1.2930e+02, xlr=1.0000e-04, time_elapsed=1.316s\n",
            "sparsity:0.8054545454545454\n",
            "########### layer stat ###########\n",
            "          features.0abs(W): min=0.0000e+00, mean=7.0072e-01, max=1.0000e+00, nnz=0.8340\n",
            "          features.3abs(W): min=0.0000e+00, mean=6.0613e-01, max=1.0000e+00, nnz=0.7806\n",
            "########### layer stat ###########\n",
            "+-----------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUJ6ERWIZTiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}