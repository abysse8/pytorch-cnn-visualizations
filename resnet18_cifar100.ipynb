{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet18-cifar100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/panda1230/pytorch-cnn-visualizations/blob/master/resnet18_cifar100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua3fJ9VdmLnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e61cb406-7b8c-4bbd-f042-64c50e8592b2"
      },
      "source": [
        "'''Initialize the network architecture'''\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "size_1 = 64   # 32 x 32\n",
        "size_2 = 64\n",
        "size_3 = 64\n",
        "size_4 = 64\n",
        "size_5 = 64\n",
        "size_6 = 128  # 16 x 16\n",
        "size_7 = 128\n",
        "size_8 = 128\n",
        "size_9 = 128\n",
        "size_10 = 256 # 8 x 8\n",
        "size_11 = 256\n",
        "size_12 = 256\n",
        "size_13 = 256\n",
        "size_14 = 512 # 4 x 4\n",
        "size_15 = 512\n",
        "size_16 = 512\n",
        "size_17 = 512\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, size_1, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm1 = nn.BatchNorm2d(size_1)\n",
        "\n",
        "        # BLOCK 1 #\n",
        "        self.conv2 = nn.Conv2d(size_1, size_2, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm2 = nn.BatchNorm2d(size_2)\n",
        "        self.conv3 = nn.Conv2d(size_2, size_3, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm3 = nn.BatchNorm2d(size_3)\n",
        "        self.shortcut1 = nn.Conv2d(size_1, size_3, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS1 = nn.BatchNorm2d(size_3)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(size_3, size_4, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm4 = nn.BatchNorm2d(size_4)\n",
        "        self.conv5 = nn.Conv2d(size_4, size_5, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm5 = nn.BatchNorm2d(size_5)\n",
        "        self.shortcut2 = nn.Conv2d(size_3, size_5, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS2 = nn.BatchNorm2d(size_5)\n",
        "\n",
        "\n",
        "        # BLOCK 2 #\n",
        "        self.conv6 = nn.Conv2d(size_5, size_6, kernel_size = 3, stride = 2, padding = 1, bias = False)\n",
        "        self.norm6 = nn.BatchNorm2d(size_6)\n",
        "        self.conv7 = nn.Conv2d(size_6, size_7, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm7 = nn.BatchNorm2d(size_7)\n",
        "        self.shortcut3 = nn.Conv2d(size_5, size_7, kernel_size = 1, stride = 2, padding = 0, bias = False)\n",
        "        self.normS3 = nn.BatchNorm2d(size_7)\n",
        "        \n",
        "        self.conv8 = nn.Conv2d(size_7, size_8, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm8 = nn.BatchNorm2d(size_8)\n",
        "        self.conv9 = nn.Conv2d(size_8, size_9, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm9 = nn.BatchNorm2d(size_9)\n",
        "        self.shortcut4 = nn.Conv2d(size_7, size_9, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS4 = nn.BatchNorm2d(size_9)\n",
        "\n",
        "\n",
        "        # BLOCK 3 #\n",
        "        self.conv10 = nn.Conv2d(size_9, size_10, kernel_size = 3, stride = 2, padding = 1, bias = False)\n",
        "        self.norm10 = nn.BatchNorm2d(size_10)\n",
        "        self.conv11 = nn.Conv2d(size_10, size_11, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm11 = nn.BatchNorm2d(size_11)\n",
        "        self.shortcut5 = nn.Conv2d(size_9, size_11, kernel_size = 1, stride = 2, padding = 0, bias = False)\n",
        "        self.normS5 = nn.BatchNorm2d(size_11)\n",
        "        \n",
        "        self.conv12 = nn.Conv2d(size_11, size_12, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm12 = nn.BatchNorm2d(size_12)\n",
        "        self.conv13 = nn.Conv2d(size_12, size_13, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm13 = nn.BatchNorm2d(size_13)\n",
        "        self.shortcut6 = nn.Conv2d(size_11, size_13, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS6 = nn.BatchNorm2d(size_13)\n",
        "\n",
        "\n",
        "        # BLOCK 4 #\n",
        "        self.conv14 = nn.Conv2d(size_13, size_14, kernel_size = 3, stride = 2, padding = 1, bias = False)\n",
        "        self.norm14 = nn.BatchNorm2d(size_14)\n",
        "        self.conv15 = nn.Conv2d(size_14, size_15, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm15 = nn.BatchNorm2d(size_15)\n",
        "        self.shortcut7 = nn.Conv2d(size_13, size_15, kernel_size = 1, stride = 2, padding = 0, bias = False)\n",
        "        self.normS7 = nn.BatchNorm2d(size_15)\n",
        "        \n",
        "        self.conv16 = nn.Conv2d(size_15, size_16, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm16 = nn.BatchNorm2d(size_16)\n",
        "        self.conv17 = nn.Conv2d(size_16, size_17, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm17 = nn.BatchNorm2d(size_17)\n",
        "        self.shortcut8 = nn.Conv2d(size_15, size_17, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS8 = nn.BatchNorm2d(size_17)\n",
        "\n",
        "        self.linear = nn.Linear(512, 100)\n",
        "\n",
        "\n",
        "    def forward(self, x0):\n",
        "        x1 = F.relu(self.norm1(self.conv1(x0)))        # x1 has size 64 (i.e. it has 64 filters)\n",
        "\n",
        "        # BLOCK 1 #\n",
        "        x2 = F.relu(self.norm2(self.conv2(x1)))         # x2 has size 64\n",
        "        x3 = F.relu(self.norm3(self.conv3(x2)))         # x3 has size 64\n",
        "        xS1 = F.relu(self.normS1(self.shortcut1(x1)))   # have to project x1 to have the same size as x3\n",
        "        x3 = x3 + xS1                                   \n",
        "        x4 = F.relu(self.norm4(self.conv4(x3)))         # x4 has size 64\n",
        "        x5 = F.relu(self.norm5(self.conv5(x4)))         # x5 has size 64\n",
        "        xS2 = F.relu(self.normS2(self.shortcut2(x3)))   # have to project x3 to have the same size as x5\n",
        "        x5 = x5 + xS2\n",
        "        \n",
        "\n",
        "        # BLOCK 2 #\n",
        "        x6 = F.relu(self.norm6(self.conv6(x5)))         # x6 has size 128\n",
        "        x7 = F.relu(self.norm7(self.conv7(x6)))         # x7 has size 128\n",
        "        xS3 = F.relu(self.normS3(self.shortcut3(x5)))   # have to project x5 to have the same size as x7\n",
        "        x7 = x7 + xS3\n",
        "        x8 = F.relu(self.norm8(self.conv8(x7)))         # x8 has size 128\n",
        "        x9 = F.relu(self.norm9(self.conv9(x8)))         # x9 has size 128\n",
        "        xS4 = F.relu(self.normS4(self.shortcut4(x7)))   # have to project x7 to have the same size as x9\n",
        "        x9 = x9 + xS4\n",
        "\n",
        "        # BLOCK 3 #\n",
        "        x10 = F.relu(self.norm10(self.conv10(x9)))      # x10 has size 256\n",
        "        x11 = F.relu(self.norm11(self.conv11(x10)))     # x11 has size 256\n",
        "        xS5 = F.relu(self.normS5(self.shortcut5(x9)))   # have to project x9 to have the same size as x11\n",
        "        x11 = x11 + xS5\n",
        "        x12 = F.relu(self.norm12(self.conv12(x11)))     # x12 has size 256\n",
        "        x13 = F.relu(self.norm13(self.conv13(x12)))     # x13 has size 256\n",
        "        xS6 = F.relu(self.normS6(self.shortcut6(x11)))  # have to project x11 to have the same size as x13\n",
        "        x13 = x13 + xS6\n",
        "\n",
        "        # BLOCK 4 #\n",
        "        x14 = F.relu(self.norm14(self.conv14(x13)))     # x14 has size 512\n",
        "        x15 = F.relu(self.norm15(self.conv15(x14)))     # x15 has size 512\n",
        "        xS7 = F.relu(self.normS7(self.shortcut7(x13)))  # have to project x13 to have the same size as x15\n",
        "        x15 = x15 + xS7\n",
        "        x16 = F.relu(self.norm16(self.conv16(x15)))     # x16 has size 512\n",
        "        x17 = F.relu(self.norm17(self.conv17(x16)))     # x17 has size 512\n",
        "        xS8 = F.relu(self.normS8(self.shortcut8(x15)))  # have to project x15 to have the same size as x17\n",
        "        x17 = x17 + xS8\n",
        "\n",
        "        x18 = F.avg_pool2d(x17, 4)\n",
        "        x18 = x18.view(x18.size(0), -1)\n",
        "        x19 = self.linear(x18)\n",
        "\n",
        "        output = x19\n",
        "        activations = [x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17]\n",
        "\n",
        "        return output, activations\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = Net()\n",
        "    #net.eval()\n",
        "    y, x = net(torch.randn(1,3,32,32))\n",
        "    print(y.size())\n",
        "\n",
        "test()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0_df8U8mRd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ded7e3b2-50b1-43a6-c082-da1580395b45"
      },
      "source": [
        "'''train network'''\n",
        "\n",
        "device = 'cuda'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "num_epochs = 210\n",
        "num_layers = 17\n",
        "\n",
        "absolute_layer_energies = np.zeros((num_epochs, num_layers+1))\n",
        "fractional_layer_energies = np.zeros((num_epochs, num_layers+1))\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./../datasets/cifar100', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./../datasets/cifar100', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "print('==> Building model..')\n",
        "net = Net()\n",
        "net = net.to(device)\n",
        "net = torch.nn.DataParallel(net)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "test_acc = []\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    activations = []\n",
        "    global absolute_layer_energies\n",
        "    global fractional_layer_energies\n",
        "    previous_time = time.process_time()\n",
        "    \n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs, activations = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        if batch_idx%100==0:\n",
        "            current_time = time.process_time()\n",
        "            print(batch_idx, len(testloader), 'Lap time (s): %.2f | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                    % (current_time - previous_time, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "            previous_time = current_time\n",
        "            \n",
        "    this_epoch_abs_energies, this_epoch_frac_energies = count_non_zeros(activations)\n",
        "    fractional_layer_energies[epoch] = this_epoch_frac_energies\n",
        "    absolute_layer_energies[epoch] = this_epoch_abs_energies\n",
        "    print('Total activation density: %.3f' % (fractional_layer_energies[epoch, 0]))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    activations = []\n",
        "    previous_time = time.process_time()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs, activations = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            acc = correct/total\n",
        "            if batch_idx%100 == 0:\n",
        "                test_acc.append(acc)\n",
        "                best_acc = max(acc, best_acc)\n",
        "                current_time = time.process_time()\n",
        "                print(batch_idx, len(testloader), 'Lap time (s): %.2f | Loss: %.3f | Acc: %.3f%% (%d/%d) | Best acc: %.3f'\n",
        "                    % (current_time - previous_time, test_loss/(batch_idx+1), 100.*correct/total, correct, total, best_acc))\n",
        "                previous_time = current_time\n",
        "            if acc>=best_acc:\n",
        "                #print('Saving')\n",
        "                torch.save(net.state_dict(),'./sample_data/resnet18_net0.pth')\n",
        "\n",
        "\n",
        "def count_non_zeros(activations): \n",
        "    \n",
        "    #returns: numpy array containing the number of non-zero activations per layer (15x1)\n",
        "    #         numpy array containing the fraction of non-zero activations per layer (15x1)\n",
        "    \n",
        "    n = 0\n",
        "    num_zeros = np.zeros((num_layers+1,), dtype = int)\n",
        "    num_non_zeros = np.zeros((num_layers+1,), dtype = int)\n",
        "    total_activations = np.zeros((num_layers+1,), dtype = int)\n",
        "    fraction_non_zero = np.zeros((num_layers+1,), dtype = float)\n",
        "    for x in activations:\n",
        "        n += 1\n",
        "        #reshape activations into a flat list\n",
        "        num_activations = x.size()[0] * x.size()[1] * x.size()[2] * x.size()[3]\n",
        "        \n",
        "        y = x.view(num_activations).tolist()\n",
        "        \n",
        "        #count how many entries are zero / non-zero\n",
        "        num_zeros[n] = y.count(0)\n",
        "        total_activations[n] = num_activations\n",
        "        num_non_zeros[n] = len(y) - num_zeros[n]\n",
        "        fraction_non_zero[n] = num_non_zeros[n].astype(float)/float(len(y))\n",
        "     \n",
        "        \n",
        "    #store total values in the zero slot\n",
        "    num_non_zeros[0] = np.sum(num_non_zeros) \n",
        "    total_activations[0] = np.sum(total_activations)\n",
        "    fraction_non_zero[0] = num_non_zeros[0].astype(float)/total_activations[0].astype(float)\n",
        "    return num_non_zeros, fraction_non_zero\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch == 70):\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "    if (epoch == 140):\n",
        "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    print('Elapsed time: %.2f' % (time.process_time()))\n",
        "    \n",
        "torch.save(fractional_layer_energies,'./sample_data/fraction_energy_net0.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Using downloaded and verified file: ./../datasets/cifar100/cifar-100-python.tar.gz\n",
            "Extracting ./../datasets/cifar100/cifar-100-python.tar.gz to ./../datasets/cifar100\n",
            "Files already downloaded and verified\n",
            "==> Building model..\n",
            "\n",
            "Epoch: 0\n",
            "0 100 Lap time (s): 0.52 | Loss: 4.694 | Acc: 1.562% (4/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 4.405 | Acc: 4.115% (1064/25856)\n",
            "Total activation density: 0.598\n",
            "0 100 Lap time (s): 0.16 | Loss: 3.960 | Acc: 7.000% (7/100) | Best acc: 0.070\n",
            "Elapsed time: 47.05\n",
            "\n",
            "Epoch: 1\n",
            "0 100 Lap time (s): 0.15 | Loss: 3.791 | Acc: 10.938% (28/256)\n",
            "100 100 Lap time (s): 11.56 | Loss: 3.688 | Acc: 11.881% (3072/25856)\n",
            "Total activation density: 0.596\n",
            "0 100 Lap time (s): 0.08 | Loss: 3.770 | Acc: 9.000% (9/100) | Best acc: 0.090\n",
            "Elapsed time: 82.33\n",
            "\n",
            "Epoch: 2\n",
            "0 100 Lap time (s): 0.14 | Loss: 3.462 | Acc: 20.312% (52/256)\n",
            "100 100 Lap time (s): 11.55 | Loss: 3.261 | Acc: 19.554% (5056/25856)\n",
            "Total activation density: 0.591\n",
            "0 100 Lap time (s): 0.07 | Loss: 3.248 | Acc: 27.000% (27/100) | Best acc: 0.270\n",
            "Elapsed time: 109.42\n",
            "\n",
            "Epoch: 3\n",
            "0 100 Lap time (s): 0.15 | Loss: 2.819 | Acc: 25.000% (64/256)\n",
            "100 100 Lap time (s): 11.57 | Loss: 2.891 | Acc: 26.508% (6854/25856)\n",
            "Total activation density: 0.587\n",
            "0 100 Lap time (s): 0.08 | Loss: 2.843 | Acc: 28.000% (28/100) | Best acc: 0.280\n",
            "Elapsed time: 144.86\n",
            "\n",
            "Epoch: 4\n",
            "0 100 Lap time (s): 0.18 | Loss: 2.548 | Acc: 33.203% (85/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 2.496 | Acc: 34.216% (8847/25856)\n",
            "Total activation density: 0.584\n",
            "0 100 Lap time (s): 0.08 | Loss: 2.628 | Acc: 28.000% (28/100) | Best acc: 0.280\n",
            "Elapsed time: 180.40\n",
            "\n",
            "Epoch: 5\n",
            "0 100 Lap time (s): 0.15 | Loss: 2.136 | Acc: 42.188% (108/256)\n",
            "100 100 Lap time (s): 11.54 | Loss: 2.148 | Acc: 41.619% (10761/25856)\n",
            "Total activation density: 0.579\n",
            "0 100 Lap time (s): 0.08 | Loss: 2.410 | Acc: 42.000% (42/100) | Best acc: 0.420\n",
            "Elapsed time: 207.52\n",
            "\n",
            "Epoch: 6\n",
            "0 100 Lap time (s): 0.13 | Loss: 1.913 | Acc: 47.266% (121/256)\n",
            "100 100 Lap time (s): 11.63 | Loss: 1.911 | Acc: 46.890% (12124/25856)\n",
            "Total activation density: 0.573\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.943 | Acc: 51.000% (51/100) | Best acc: 0.510\n",
            "Elapsed time: 234.72\n",
            "\n",
            "Epoch: 7\n",
            "0 100 Lap time (s): 0.14 | Loss: 1.708 | Acc: 50.781% (130/256)\n",
            "100 100 Lap time (s): 11.62 | Loss: 1.707 | Acc: 51.887% (13416/25856)\n",
            "Total activation density: 0.568\n",
            "0 100 Lap time (s): 0.08 | Loss: 2.244 | Acc: 41.000% (41/100) | Best acc: 0.510\n",
            "Elapsed time: 261.72\n",
            "\n",
            "Epoch: 8\n",
            "0 100 Lap time (s): 0.15 | Loss: 1.576 | Acc: 54.297% (139/256)\n",
            "100 100 Lap time (s): 11.62 | Loss: 1.581 | Acc: 55.202% (14273/25856)\n",
            "Total activation density: 0.565\n",
            "0 100 Lap time (s): 0.07 | Loss: 1.817 | Acc: 56.000% (56/100) | Best acc: 0.560\n",
            "Elapsed time: 288.82\n",
            "\n",
            "Epoch: 9\n",
            "0 100 Lap time (s): 0.16 | Loss: 1.468 | Acc: 57.031% (146/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 1.459 | Acc: 57.948% (14983/25856)\n",
            "Total activation density: 0.560\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.921 | Acc: 53.000% (53/100) | Best acc: 0.560\n",
            "Elapsed time: 315.80\n",
            "\n",
            "Epoch: 10\n",
            "0 100 Lap time (s): 0.14 | Loss: 1.340 | Acc: 60.938% (156/256)\n",
            "100 100 Lap time (s): 11.58 | Loss: 1.384 | Acc: 60.272% (15584/25856)\n",
            "Total activation density: 0.557\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.576 | Acc: 60.000% (60/100) | Best acc: 0.600\n",
            "Elapsed time: 342.81\n",
            "\n",
            "Epoch: 11\n",
            "0 100 Lap time (s): 0.16 | Loss: 1.304 | Acc: 64.844% (166/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 1.292 | Acc: 62.450% (16147/25856)\n",
            "Total activation density: 0.552\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.620 | Acc: 54.000% (54/100) | Best acc: 0.600\n",
            "Elapsed time: 369.80\n",
            "\n",
            "Epoch: 12\n",
            "0 100 Lap time (s): 0.15 | Loss: 1.103 | Acc: 66.797% (171/256)\n",
            "100 100 Lap time (s): 11.64 | Loss: 1.228 | Acc: 64.287% (16622/25856)\n",
            "Total activation density: 0.551\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.781 | Acc: 57.000% (57/100) | Best acc: 0.600\n",
            "Elapsed time: 396.77\n",
            "\n",
            "Epoch: 13\n",
            "0 100 Lap time (s): 0.15 | Loss: 1.161 | Acc: 66.797% (171/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 1.169 | Acc: 65.737% (16997/25856)\n",
            "Total activation density: 0.549\n",
            "0 100 Lap time (s): 0.07 | Loss: 1.831 | Acc: 53.000% (53/100) | Best acc: 0.600\n",
            "Elapsed time: 423.83\n",
            "\n",
            "Epoch: 14\n",
            "0 100 Lap time (s): 0.15 | Loss: 1.051 | Acc: 69.531% (178/256)\n",
            "100 100 Lap time (s): 11.57 | Loss: 1.129 | Acc: 66.785% (17268/25856)\n",
            "Total activation density: 0.547\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.695 | Acc: 57.000% (57/100) | Best acc: 0.600\n",
            "Elapsed time: 450.83\n",
            "\n",
            "Epoch: 15\n",
            "0 100 Lap time (s): 0.15 | Loss: 1.111 | Acc: 65.234% (167/256)\n",
            "100 100 Lap time (s): 11.61 | Loss: 1.070 | Acc: 68.294% (17658/25856)\n",
            "Total activation density: 0.549\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.861 | Acc: 54.000% (54/100) | Best acc: 0.600\n",
            "Elapsed time: 477.77\n",
            "\n",
            "Epoch: 16\n",
            "0 100 Lap time (s): 0.16 | Loss: 1.001 | Acc: 71.875% (184/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 1.033 | Acc: 68.924% (17821/25856)\n",
            "Total activation density: 0.546\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.570 | Acc: 57.000% (57/100) | Best acc: 0.600\n",
            "Elapsed time: 504.88\n",
            "\n",
            "Epoch: 17\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.935 | Acc: 74.219% (190/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 1.017 | Acc: 69.458% (17959/25856)\n",
            "Total activation density: 0.547\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.467 | Acc: 61.000% (61/100) | Best acc: 0.610\n",
            "Elapsed time: 532.22\n",
            "\n",
            "Epoch: 18\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.866 | Acc: 74.609% (191/256)\n",
            "100 100 Lap time (s): 11.61 | Loss: 0.980 | Acc: 70.634% (18263/25856)\n",
            "Total activation density: 0.548\n",
            "0 100 Lap time (s): 0.07 | Loss: 1.738 | Acc: 56.000% (56/100) | Best acc: 0.610\n",
            "Elapsed time: 559.23\n",
            "\n",
            "Epoch: 19\n",
            "0 100 Lap time (s): 0.15 | Loss: 1.065 | Acc: 67.969% (174/256)\n",
            "100 100 Lap time (s): 11.63 | Loss: 0.950 | Acc: 71.581% (18508/25856)\n",
            "Total activation density: 0.550\n",
            "0 100 Lap time (s): 0.07 | Loss: 1.688 | Acc: 62.000% (62/100) | Best acc: 0.620\n",
            "Elapsed time: 586.33\n",
            "\n",
            "Epoch: 20\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.815 | Acc: 75.781% (194/256)\n",
            "100 100 Lap time (s): 11.63 | Loss: 0.907 | Acc: 72.575% (18765/25856)\n",
            "Total activation density: 0.549\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.610 | Acc: 58.000% (58/100) | Best acc: 0.620\n",
            "Elapsed time: 613.35\n",
            "\n",
            "Epoch: 21\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.875 | Acc: 75.781% (194/256)\n",
            "100 100 Lap time (s): 11.58 | Loss: 0.900 | Acc: 73.163% (18917/25856)\n",
            "Total activation density: 0.547\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.563 | Acc: 63.000% (63/100) | Best acc: 0.630\n",
            "Elapsed time: 640.60\n",
            "\n",
            "Epoch: 22\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.743 | Acc: 75.391% (193/256)\n",
            "100 100 Lap time (s): 11.58 | Loss: 0.868 | Acc: 73.476% (18998/25856)\n",
            "Total activation density: 0.549\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.724 | Acc: 55.000% (55/100) | Best acc: 0.630\n",
            "Elapsed time: 667.60\n",
            "\n",
            "Epoch: 23\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.744 | Acc: 78.516% (201/256)\n",
            "100 100 Lap time (s): 11.62 | Loss: 0.846 | Acc: 74.420% (19242/25856)\n",
            "Total activation density: 0.545\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.809 | Acc: 56.000% (56/100) | Best acc: 0.630\n",
            "Elapsed time: 694.64\n",
            "\n",
            "Epoch: 24\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.813 | Acc: 74.219% (190/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 0.837 | Acc: 74.664% (19305/25856)\n",
            "Total activation density: 0.548\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.487 | Acc: 67.000% (67/100) | Best acc: 0.670\n",
            "Elapsed time: 721.77\n",
            "\n",
            "Epoch: 25\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.786 | Acc: 76.953% (197/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 0.822 | Acc: 74.845% (19352/25856)\n",
            "Total activation density: 0.546\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.813 | Acc: 57.000% (57/100) | Best acc: 0.670\n",
            "Elapsed time: 748.67\n",
            "\n",
            "Epoch: 26\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.851 | Acc: 74.219% (190/256)\n",
            "100 100 Lap time (s): 11.61 | Loss: 0.814 | Acc: 75.166% (19435/25856)\n",
            "Total activation density: 0.543\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.618 | Acc: 58.000% (58/100) | Best acc: 0.670\n",
            "Elapsed time: 775.64\n",
            "\n",
            "Epoch: 27\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.754 | Acc: 78.516% (201/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 0.795 | Acc: 75.878% (19619/25856)\n",
            "Total activation density: 0.547\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.797 | Acc: 59.000% (59/100) | Best acc: 0.670\n",
            "Elapsed time: 802.47\n",
            "\n",
            "Epoch: 28\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.718 | Acc: 79.688% (204/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 0.743 | Acc: 77.468% (20030/25856)\n",
            "Total activation density: 0.547\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.626 | Acc: 61.000% (61/100) | Best acc: 0.670\n",
            "Elapsed time: 829.33\n",
            "\n",
            "Epoch: 29\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.645 | Acc: 80.859% (207/256)\n",
            "100 100 Lap time (s): 11.62 | Loss: 0.752 | Acc: 76.976% (19903/25856)\n",
            "Total activation density: 0.543\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.481 | Acc: 64.000% (64/100) | Best acc: 0.670\n",
            "Elapsed time: 856.31\n",
            "\n",
            "Epoch: 30\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.775 | Acc: 75.781% (194/256)\n",
            "100 100 Lap time (s): 11.62 | Loss: 0.732 | Acc: 77.622% (20070/25856)\n",
            "Total activation density: 0.548\n",
            "0 100 Lap time (s): 0.07 | Loss: 1.568 | Acc: 62.000% (62/100) | Best acc: 0.670\n",
            "Elapsed time: 883.29\n",
            "\n",
            "Epoch: 31\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.759 | Acc: 80.859% (207/256)\n",
            "100 100 Lap time (s): 11.57 | Loss: 0.749 | Acc: 77.139% (19945/25856)\n",
            "Total activation density: 0.544\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.715 | Acc: 62.000% (62/100) | Best acc: 0.670\n",
            "Elapsed time: 910.16\n",
            "\n",
            "Epoch: 32\n",
            "0 100 Lap time (s): 0.18 | Loss: 0.667 | Acc: 77.734% (199/256)\n",
            "100 100 Lap time (s): 11.57 | Loss: 0.719 | Acc: 78.117% (20198/25856)\n",
            "Total activation density: 0.548\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.722 | Acc: 56.000% (56/100) | Best acc: 0.670\n",
            "Elapsed time: 937.13\n",
            "\n",
            "Epoch: 33\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.599 | Acc: 83.594% (214/256)\n",
            "100 100 Lap time (s): 11.56 | Loss: 0.702 | Acc: 78.554% (20311/25856)\n",
            "Total activation density: 0.544\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.483 | Acc: 63.000% (63/100) | Best acc: 0.670\n",
            "Elapsed time: 964.07\n",
            "\n",
            "Epoch: 34\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.591 | Acc: 81.250% (208/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 0.707 | Acc: 78.307% (20247/25856)\n",
            "Total activation density: 0.545\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.649 | Acc: 58.000% (58/100) | Best acc: 0.670\n",
            "Elapsed time: 990.95\n",
            "\n",
            "Epoch: 35\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.669 | Acc: 80.469% (206/256)\n",
            "100 100 Lap time (s): 11.58 | Loss: 0.680 | Acc: 79.103% (20453/25856)\n",
            "Total activation density: 0.547\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.701 | Acc: 59.000% (59/100) | Best acc: 0.670\n",
            "Elapsed time: 1017.94\n",
            "\n",
            "Epoch: 36\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.538 | Acc: 83.594% (214/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 0.694 | Acc: 78.806% (20376/25856)\n",
            "Total activation density: 0.547\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.526 | Acc: 62.000% (62/100) | Best acc: 0.670\n",
            "Elapsed time: 1044.93\n",
            "\n",
            "Epoch: 37\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.687 | Acc: 75.391% (193/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 0.657 | Acc: 79.641% (20592/25856)\n",
            "Total activation density: 0.545\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.857 | Acc: 57.000% (57/100) | Best acc: 0.670\n",
            "Elapsed time: 1071.85\n",
            "\n",
            "Epoch: 38\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.669 | Acc: 82.031% (210/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 0.659 | Acc: 79.943% (20670/25856)\n",
            "Total activation density: 0.545\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.688 | Acc: 60.000% (60/100) | Best acc: 0.670\n",
            "Elapsed time: 1098.78\n",
            "\n",
            "Epoch: 39\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.695 | Acc: 78.125% (200/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.657 | Acc: 79.711% (20610/25856)\n",
            "Total activation density: 0.544\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.977 | Acc: 59.000% (59/100) | Best acc: 0.670\n",
            "Elapsed time: 1125.64\n",
            "\n",
            "Epoch: 40\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.424 | Acc: 88.672% (227/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 0.657 | Acc: 79.834% (20642/25856)\n",
            "Total activation density: 0.545\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.795 | Acc: 59.000% (59/100) | Best acc: 0.670\n",
            "Elapsed time: 1152.54\n",
            "\n",
            "Epoch: 41\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.724 | Acc: 75.781% (194/256)\n",
            "100 100 Lap time (s): 11.61 | Loss: 0.651 | Acc: 79.877% (20653/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.765 | Acc: 56.000% (56/100) | Best acc: 0.670\n",
            "Elapsed time: 1179.38\n",
            "\n",
            "Epoch: 42\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.588 | Acc: 81.641% (209/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 0.633 | Acc: 80.527% (20821/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.712 | Acc: 62.000% (62/100) | Best acc: 0.670\n",
            "Elapsed time: 1206.30\n",
            "\n",
            "Epoch: 43\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.725 | Acc: 78.906% (202/256)\n",
            "100 100 Lap time (s): 11.61 | Loss: 0.621 | Acc: 80.805% (20893/25856)\n",
            "Total activation density: 0.541\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.762 | Acc: 63.000% (63/100) | Best acc: 0.670\n",
            "Elapsed time: 1233.26\n",
            "\n",
            "Epoch: 44\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.499 | Acc: 84.375% (216/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 0.625 | Acc: 80.859% (20907/25856)\n",
            "Total activation density: 0.539\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.885 | Acc: 67.000% (67/100) | Best acc: 0.670\n",
            "Elapsed time: 1260.29\n",
            "\n",
            "Epoch: 45\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.618 | Acc: 82.031% (210/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.637 | Acc: 80.496% (20813/25856)\n",
            "Total activation density: 0.538\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.639 | Acc: 61.000% (61/100) | Best acc: 0.670\n",
            "Elapsed time: 1287.14\n",
            "\n",
            "Epoch: 46\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.609 | Acc: 80.859% (207/256)\n",
            "100 100 Lap time (s): 11.54 | Loss: 0.617 | Acc: 80.898% (20917/25856)\n",
            "Total activation density: 0.539\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.416 | Acc: 62.000% (62/100) | Best acc: 0.670\n",
            "Elapsed time: 1314.01\n",
            "\n",
            "Epoch: 47\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.608 | Acc: 80.859% (207/256)\n",
            "100 100 Lap time (s): 11.62 | Loss: 0.620 | Acc: 80.817% (20896/25856)\n",
            "Total activation density: 0.541\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.499 | Acc: 64.000% (64/100) | Best acc: 0.670\n",
            "Elapsed time: 1340.98\n",
            "\n",
            "Epoch: 48\n",
            "0 100 Lap time (s): 0.18 | Loss: 0.560 | Acc: 82.422% (211/256)\n",
            "100 100 Lap time (s): 11.57 | Loss: 0.604 | Acc: 81.405% (21048/25856)\n",
            "Total activation density: 0.541\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.588 | Acc: 62.000% (62/100) | Best acc: 0.670\n",
            "Elapsed time: 1367.96\n",
            "\n",
            "Epoch: 49\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.618 | Acc: 79.688% (204/256)\n",
            "100 100 Lap time (s): 11.58 | Loss: 0.585 | Acc: 82.337% (21289/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.774 | Acc: 60.000% (60/100) | Best acc: 0.670\n",
            "Elapsed time: 1394.81\n",
            "\n",
            "Epoch: 50\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.646 | Acc: 80.078% (205/256)\n",
            "100 100 Lap time (s): 11.58 | Loss: 0.613 | Acc: 80.995% (20942/25856)\n",
            "Total activation density: 0.539\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.564 | Acc: 63.000% (63/100) | Best acc: 0.670\n",
            "Elapsed time: 1421.72\n",
            "\n",
            "Epoch: 51\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.470 | Acc: 85.938% (220/256)\n",
            "100 100 Lap time (s): 11.57 | Loss: 0.588 | Acc: 81.869% (21168/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.563 | Acc: 63.000% (63/100) | Best acc: 0.670\n",
            "Elapsed time: 1448.66\n",
            "\n",
            "Epoch: 52\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.599 | Acc: 82.031% (210/256)\n",
            "100 100 Lap time (s): 11.61 | Loss: 0.597 | Acc: 81.432% (21055/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.632 | Acc: 55.000% (55/100) | Best acc: 0.670\n",
            "Elapsed time: 1475.64\n",
            "\n",
            "Epoch: 53\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.646 | Acc: 79.688% (204/256)\n",
            "100 100 Lap time (s): 11.62 | Loss: 0.598 | Acc: 81.486% (21069/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.680 | Acc: 62.000% (62/100) | Best acc: 0.670\n",
            "Elapsed time: 1502.64\n",
            "\n",
            "Epoch: 54\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.471 | Acc: 81.641% (209/256)\n",
            "100 100 Lap time (s): 11.58 | Loss: 0.589 | Acc: 81.598% (21098/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.464 | Acc: 66.000% (66/100) | Best acc: 0.670\n",
            "Elapsed time: 1529.52\n",
            "\n",
            "Epoch: 55\n",
            "0 100 Lap time (s): 0.18 | Loss: 0.639 | Acc: 80.469% (206/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.576 | Acc: 82.209% (21256/25856)\n",
            "Total activation density: 0.538\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.694 | Acc: 57.000% (57/100) | Best acc: 0.670\n",
            "Elapsed time: 1556.46\n",
            "\n",
            "Epoch: 56\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.528 | Acc: 84.766% (217/256)\n",
            "100 100 Lap time (s): 11.57 | Loss: 0.589 | Acc: 81.900% (21176/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.695 | Acc: 59.000% (59/100) | Best acc: 0.670\n",
            "Elapsed time: 1583.33\n",
            "\n",
            "Epoch: 57\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.577 | Acc: 85.547% (219/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 0.563 | Acc: 82.519% (21336/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.357 | Acc: 65.000% (65/100) | Best acc: 0.670\n",
            "Elapsed time: 1610.33\n",
            "\n",
            "Epoch: 58\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.595 | Acc: 83.203% (213/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 0.570 | Acc: 82.696% (21382/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.964 | Acc: 54.000% (54/100) | Best acc: 0.670\n",
            "Elapsed time: 1637.24\n",
            "\n",
            "Epoch: 59\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.535 | Acc: 81.250% (208/256)\n",
            "100 100 Lap time (s): 11.61 | Loss: 0.578 | Acc: 82.136% (21237/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.687 | Acc: 62.000% (62/100) | Best acc: 0.670\n",
            "Elapsed time: 1664.18\n",
            "\n",
            "Epoch: 60\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.497 | Acc: 85.938% (220/256)\n",
            "100 100 Lap time (s): 11.61 | Loss: 0.569 | Acc: 82.700% (21383/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.440 | Acc: 61.000% (61/100) | Best acc: 0.670\n",
            "Elapsed time: 1691.08\n",
            "\n",
            "Epoch: 61\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.472 | Acc: 85.156% (218/256)\n",
            "100 100 Lap time (s): 11.60 | Loss: 0.556 | Acc: 82.646% (21369/25856)\n",
            "Total activation density: 0.538\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.870 | Acc: 57.000% (57/100) | Best acc: 0.670\n",
            "Elapsed time: 1717.99\n",
            "\n",
            "Epoch: 62\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.598 | Acc: 79.688% (204/256)\n",
            "100 100 Lap time (s): 11.61 | Loss: 0.570 | Acc: 82.287% (21276/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.924 | Acc: 56.000% (56/100) | Best acc: 0.670\n",
            "Elapsed time: 1744.96\n",
            "\n",
            "Epoch: 63\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.599 | Acc: 82.812% (212/256)\n",
            "100 100 Lap time (s): 11.59 | Loss: 0.558 | Acc: 82.805% (21410/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.583 | Acc: 61.000% (61/100) | Best acc: 0.670\n",
            "Elapsed time: 1771.92\n",
            "\n",
            "Epoch: 64\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.543 | Acc: 83.203% (213/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.560 | Acc: 82.565% (21348/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.07 | Loss: 1.569 | Acc: 61.000% (61/100) | Best acc: 0.670\n",
            "Elapsed time: 1798.46\n",
            "\n",
            "Epoch: 65\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.478 | Acc: 84.375% (216/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.560 | Acc: 82.584% (21353/25856)\n",
            "Total activation density: 0.540\n",
            "0 100 Lap time (s): 0.07 | Loss: 1.591 | Acc: 60.000% (60/100) | Best acc: 0.670\n",
            "Elapsed time: 1825.17\n",
            "\n",
            "Epoch: 66\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.608 | Acc: 80.469% (206/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.557 | Acc: 82.561% (21347/25856)\n",
            "Total activation density: 0.541\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.612 | Acc: 64.000% (64/100) | Best acc: 0.670\n",
            "Elapsed time: 1851.78\n",
            "\n",
            "Epoch: 67\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.507 | Acc: 86.328% (221/256)\n",
            "100 100 Lap time (s): 11.46 | Loss: 0.545 | Acc: 82.936% (21444/25856)\n",
            "Total activation density: 0.541\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.511 | Acc: 66.000% (66/100) | Best acc: 0.670\n",
            "Elapsed time: 1878.36\n",
            "\n",
            "Epoch: 68\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.485 | Acc: 82.812% (212/256)\n",
            "100 100 Lap time (s): 11.40 | Loss: 0.552 | Acc: 83.145% (21498/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.536 | Acc: 67.000% (67/100) | Best acc: 0.670\n",
            "Elapsed time: 1904.93\n",
            "\n",
            "Epoch: 69\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.460 | Acc: 84.375% (216/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.550 | Acc: 82.681% (21378/25856)\n",
            "Total activation density: 0.534\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.638 | Acc: 64.000% (64/100) | Best acc: 0.670\n",
            "Elapsed time: 1931.54\n",
            "\n",
            "Epoch: 70\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.544 | Acc: 85.938% (220/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.310 | Acc: 91.019% (23534/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.035 | Acc: 75.000% (75/100) | Best acc: 0.750\n",
            "Elapsed time: 1960.05\n",
            "\n",
            "Epoch: 71\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.199 | Acc: 94.141% (241/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.163 | Acc: 95.819% (24775/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 1.012 | Acc: 74.000% (74/100) | Best acc: 0.750\n",
            "Elapsed time: 1994.11\n",
            "\n",
            "Epoch: 72\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.124 | Acc: 97.656% (250/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.127 | Acc: 97.057% (25095/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.973 | Acc: 76.000% (76/100) | Best acc: 0.760\n",
            "Elapsed time: 2021.73\n",
            "\n",
            "Epoch: 73\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.117 | Acc: 97.656% (250/256)\n",
            "100 100 Lap time (s): 11.42 | Loss: 0.106 | Acc: 97.664% (25252/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.932 | Acc: 76.000% (76/100) | Best acc: 0.760\n",
            "Elapsed time: 2051.54\n",
            "\n",
            "Epoch: 74\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.129 | Acc: 95.703% (245/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.090 | Acc: 98.058% (25354/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.924 | Acc: 77.000% (77/100) | Best acc: 0.770\n",
            "Elapsed time: 2078.62\n",
            "\n",
            "Epoch: 75\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.057 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.46 | Loss: 0.078 | Acc: 98.449% (25455/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.906 | Acc: 79.000% (79/100) | Best acc: 0.790\n",
            "Elapsed time: 2105.57\n",
            "\n",
            "Epoch: 76\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.069 | Acc: 98.828% (253/256)\n",
            "100 100 Lap time (s): 11.42 | Loss: 0.070 | Acc: 98.697% (25519/25856)\n",
            "Total activation density: 0.538\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.939 | Acc: 77.000% (77/100) | Best acc: 0.790\n",
            "Elapsed time: 2132.34\n",
            "\n",
            "Epoch: 77\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.072 | Acc: 98.047% (251/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.062 | Acc: 98.890% (25569/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.885 | Acc: 79.000% (79/100) | Best acc: 0.790\n",
            "Elapsed time: 2159.35\n",
            "\n",
            "Epoch: 78\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.049 | Acc: 99.219% (254/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.057 | Acc: 99.064% (25614/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.903 | Acc: 77.000% (77/100) | Best acc: 0.790\n",
            "Elapsed time: 2186.22\n",
            "\n",
            "Epoch: 79\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.043 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.050 | Acc: 99.257% (25664/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.913 | Acc: 75.000% (75/100) | Best acc: 0.790\n",
            "Elapsed time: 2213.04\n",
            "\n",
            "Epoch: 80\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.046 | Acc: 99.219% (254/256)\n",
            "100 100 Lap time (s): 11.46 | Loss: 0.048 | Acc: 99.261% (25665/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.07 | Loss: 0.937 | Acc: 78.000% (78/100) | Best acc: 0.790\n",
            "Elapsed time: 2239.76\n",
            "\n",
            "Epoch: 81\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.048 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.40 | Loss: 0.043 | Acc: 99.428% (25708/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.924 | Acc: 79.000% (79/100) | Best acc: 0.790\n",
            "Elapsed time: 2266.61\n",
            "\n",
            "Epoch: 82\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.036 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.042 | Acc: 99.420% (25706/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.915 | Acc: 78.000% (78/100) | Best acc: 0.790\n",
            "Elapsed time: 2293.41\n",
            "\n",
            "Epoch: 83\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.040 | Acc: 99.219% (254/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.038 | Acc: 99.489% (25724/25856)\n",
            "Total activation density: 0.538\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.937 | Acc: 80.000% (80/100) | Best acc: 0.800\n",
            "Elapsed time: 2320.18\n",
            "\n",
            "Epoch: 84\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.064 | Acc: 98.047% (251/256)\n",
            "100 100 Lap time (s): 11.39 | Loss: 0.035 | Acc: 99.528% (25734/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.902 | Acc: 78.000% (78/100) | Best acc: 0.800\n",
            "Elapsed time: 2346.80\n",
            "\n",
            "Epoch: 85\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.034 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.42 | Loss: 0.034 | Acc: 99.602% (25753/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.912 | Acc: 78.000% (78/100) | Best acc: 0.800\n",
            "Elapsed time: 2373.50\n",
            "\n",
            "Epoch: 86\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.032 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.033 | Acc: 99.640% (25763/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.928 | Acc: 79.000% (79/100) | Best acc: 0.800\n",
            "Elapsed time: 2400.25\n",
            "\n",
            "Epoch: 87\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.023 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.46 | Loss: 0.029 | Acc: 99.733% (25787/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.901 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 2426.99\n",
            "\n",
            "Epoch: 88\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.031 | Acc: 99.219% (254/256)\n",
            "100 100 Lap time (s): 11.42 | Loss: 0.029 | Acc: 99.733% (25787/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.898 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 2453.64\n",
            "\n",
            "Epoch: 89\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.030 | Acc: 99.219% (254/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.027 | Acc: 99.791% (25802/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.891 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 2480.24\n",
            "\n",
            "Epoch: 90\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.035 | Acc: 99.219% (254/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.027 | Acc: 99.752% (25792/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.910 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 2506.94\n",
            "\n",
            "Epoch: 91\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.026 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.42 | Loss: 0.026 | Acc: 99.780% (25799/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.869 | Acc: 76.000% (76/100) | Best acc: 0.810\n",
            "Elapsed time: 2533.52\n",
            "\n",
            "Epoch: 92\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.027 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.024 | Acc: 99.803% (25805/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.904 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 2560.09\n",
            "\n",
            "Epoch: 93\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.019 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.023 | Acc: 99.838% (25814/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.890 | Acc: 77.000% (77/100) | Best acc: 0.810\n",
            "Elapsed time: 2586.73\n",
            "\n",
            "Epoch: 94\n",
            "0 100 Lap time (s): 0.18 | Loss: 0.022 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.022 | Acc: 99.857% (25819/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.945 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 2613.43\n",
            "\n",
            "Epoch: 95\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.016 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.022 | Acc: 99.853% (25818/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.916 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 2640.09\n",
            "\n",
            "Epoch: 96\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.023 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.40 | Loss: 0.021 | Acc: 99.857% (25819/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.916 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 2666.73\n",
            "\n",
            "Epoch: 97\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.020 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.40 | Loss: 0.021 | Acc: 99.880% (25825/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.910 | Acc: 77.000% (77/100) | Best acc: 0.810\n",
            "Elapsed time: 2693.27\n",
            "\n",
            "Epoch: 98\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.027 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.020 | Acc: 99.880% (25825/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.920 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 2719.87\n",
            "\n",
            "Epoch: 99\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.016 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.019 | Acc: 99.896% (25829/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.888 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 2746.34\n",
            "\n",
            "Epoch: 100\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.022 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.019 | Acc: 99.903% (25831/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.937 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 2773.00\n",
            "\n",
            "Epoch: 101\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.017 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.019 | Acc: 99.892% (25828/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.880 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 2799.72\n",
            "\n",
            "Epoch: 102\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.016 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.41 | Loss: 0.019 | Acc: 99.907% (25832/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.887 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 2826.32\n",
            "\n",
            "Epoch: 103\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.030 | Acc: 99.219% (254/256)\n",
            "100 100 Lap time (s): 11.41 | Loss: 0.019 | Acc: 99.872% (25823/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.928 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 2852.85\n",
            "\n",
            "Epoch: 104\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.017 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.018 | Acc: 99.907% (25832/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.928 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 2879.46\n",
            "\n",
            "Epoch: 105\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.023 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.42 | Loss: 0.018 | Acc: 99.938% (25840/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.921 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 2905.96\n",
            "\n",
            "Epoch: 106\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.015 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.46 | Loss: 0.018 | Acc: 99.938% (25840/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.893 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 2932.60\n",
            "\n",
            "Epoch: 107\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.018 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.018 | Acc: 99.896% (25829/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.894 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 2959.21\n",
            "\n",
            "Epoch: 108\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.013 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.017 | Acc: 99.919% (25835/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.883 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 2985.90\n",
            "\n",
            "Epoch: 109\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.020 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.46 | Loss: 0.016 | Acc: 99.961% (25846/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.885 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3012.50\n",
            "\n",
            "Epoch: 110\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.014 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.016 | Acc: 99.903% (25831/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.845 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3039.12\n",
            "\n",
            "Epoch: 111\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.015 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.016 | Acc: 99.923% (25836/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.833 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3065.72\n",
            "\n",
            "Epoch: 112\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.023 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.016 | Acc: 99.923% (25836/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.880 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 3092.39\n",
            "\n",
            "Epoch: 113\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.013 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.41 | Loss: 0.016 | Acc: 99.915% (25834/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.890 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3118.92\n",
            "\n",
            "Epoch: 114\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.014 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.44 | Loss: 0.016 | Acc: 99.930% (25838/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.911 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3145.58\n",
            "\n",
            "Epoch: 115\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.013 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.015 | Acc: 99.938% (25840/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.902 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3172.14\n",
            "\n",
            "Epoch: 116\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.016 | Acc: 99.927% (25837/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.906 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 3198.97\n",
            "\n",
            "Epoch: 117\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.015 | Acc: 99.934% (25839/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.09 | Loss: 0.904 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3225.77\n",
            "\n",
            "Epoch: 118\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.015 | Acc: 99.950% (25843/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.09 | Loss: 0.858 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3252.33\n",
            "\n",
            "Epoch: 119\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.016 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.015 | Acc: 99.930% (25838/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.870 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3278.93\n",
            "\n",
            "Epoch: 120\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.43 | Loss: 0.015 | Acc: 99.950% (25843/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.882 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3305.59\n",
            "\n",
            "Epoch: 121\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.40 | Loss: 0.015 | Acc: 99.938% (25840/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.904 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3332.15\n",
            "\n",
            "Epoch: 122\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.015 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.014 | Acc: 99.942% (25841/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.862 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 3359.06\n",
            "\n",
            "Epoch: 123\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.014 | Acc: 99.930% (25838/25856)\n",
            "Total activation density: 0.538\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.860 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 3386.08\n",
            "\n",
            "Epoch: 124\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.013 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.013 | Acc: 99.969% (25848/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.890 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 3412.87\n",
            "\n",
            "Epoch: 125\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.012 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.42 | Loss: 0.014 | Acc: 99.950% (25843/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.874 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3439.48\n",
            "\n",
            "Epoch: 126\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.50 | Loss: 0.014 | Acc: 99.946% (25842/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.893 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3466.20\n",
            "\n",
            "Epoch: 127\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.018 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.50 | Loss: 0.016 | Acc: 99.876% (25824/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.910 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3492.86\n",
            "\n",
            "Epoch: 128\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.021 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.017 | Acc: 99.853% (25818/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.924 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3519.55\n",
            "\n",
            "Epoch: 129\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.012 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.014 | Acc: 99.934% (25839/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.921 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 3546.20\n",
            "\n",
            "Epoch: 130\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.012 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.50 | Loss: 0.014 | Acc: 99.930% (25838/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.936 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3572.79\n",
            "\n",
            "Epoch: 131\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.017 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.013 | Acc: 99.946% (25842/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.906 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 3599.58\n",
            "\n",
            "Epoch: 132\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.47 | Loss: 0.015 | Acc: 99.919% (25835/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.879 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 3626.36\n",
            "\n",
            "Epoch: 133\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.015 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.47 | Loss: 0.014 | Acc: 99.961% (25846/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.875 | Acc: 77.000% (77/100) | Best acc: 0.810\n",
            "Elapsed time: 3652.89\n",
            "\n",
            "Epoch: 134\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.013 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.908 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3679.55\n",
            "\n",
            "Epoch: 135\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.014 | Acc: 99.915% (25834/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.851 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3706.26\n",
            "\n",
            "Epoch: 136\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.013 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.47 | Loss: 0.013 | Acc: 99.927% (25837/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.897 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3732.86\n",
            "\n",
            "Epoch: 137\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.012 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.013 | Acc: 99.946% (25842/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.891 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 3759.67\n",
            "\n",
            "Epoch: 138\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.013 | Acc: 99.930% (25838/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.959 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3786.26\n",
            "\n",
            "Epoch: 139\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.012 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.50 | Loss: 0.014 | Acc: 99.930% (25838/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.854 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 3812.86\n",
            "\n",
            "Epoch: 140\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.013 | Acc: 99.934% (25839/25856)\n",
            "Total activation density: 0.534\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.882 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3839.59\n",
            "\n",
            "Epoch: 141\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.011 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.07 | Loss: 0.886 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 3866.35\n",
            "\n",
            "Epoch: 142\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.011 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.09 | Loss: 0.881 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 3892.92\n",
            "\n",
            "Epoch: 143\n",
            "0 100 Lap time (s): 0.18 | Loss: 0.014 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.011 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.09 | Loss: 0.899 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 3919.58\n",
            "\n",
            "Epoch: 144\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.011 | Acc: 99.961% (25846/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.899 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3946.23\n",
            "\n",
            "Epoch: 145\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.010 | Acc: 99.992% (25854/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.890 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 3972.91\n",
            "\n",
            "Epoch: 146\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.011 | Acc: 99.950% (25843/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.896 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 3999.66\n",
            "\n",
            "Epoch: 147\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.012 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.52 | Loss: 0.010 | Acc: 99.973% (25849/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.883 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4026.32\n",
            "\n",
            "Epoch: 148\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.010 | Acc: 99.977% (25850/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.870 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4052.98\n",
            "\n",
            "Epoch: 149\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.010 | Acc: 99.981% (25851/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.870 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4079.77\n",
            "\n",
            "Epoch: 150\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.008 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.010 | Acc: 99.973% (25849/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.879 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4106.55\n",
            "\n",
            "Epoch: 151\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.50 | Loss: 0.011 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.876 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4133.35\n",
            "\n",
            "Epoch: 152\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.022 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.52 | Loss: 0.010 | Acc: 99.981% (25851/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.889 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4160.21\n",
            "\n",
            "Epoch: 153\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.010 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.879 | Acc: 77.000% (77/100) | Best acc: 0.810\n",
            "Elapsed time: 4186.96\n",
            "\n",
            "Epoch: 154\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.010 | Acc: 99.973% (25849/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.885 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4213.81\n",
            "\n",
            "Epoch: 155\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.54 | Loss: 0.010 | Acc: 99.957% (25845/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.894 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4240.61\n",
            "\n",
            "Epoch: 156\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.010 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.888 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4267.36\n",
            "\n",
            "Epoch: 157\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.56 | Loss: 0.010 | Acc: 99.961% (25846/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.866 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4294.29\n",
            "\n",
            "Epoch: 158\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.008 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.010 | Acc: 99.981% (25851/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.871 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4320.98\n",
            "\n",
            "Epoch: 159\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.008 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.010 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.874 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4347.76\n",
            "\n",
            "Epoch: 160\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.50 | Loss: 0.010 | Acc: 99.973% (25849/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.872 | Acc: 77.000% (77/100) | Best acc: 0.810\n",
            "Elapsed time: 4374.52\n",
            "\n",
            "Epoch: 161\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.55 | Loss: 0.010 | Acc: 99.981% (25851/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.878 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4401.24\n",
            "\n",
            "Epoch: 162\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.50 | Loss: 0.010 | Acc: 99.985% (25852/25856)\n",
            "Total activation density: 0.534\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.868 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4428.07\n",
            "\n",
            "Epoch: 163\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.010 | Acc: 99.969% (25848/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.889 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4454.78\n",
            "\n",
            "Epoch: 164\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.010 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.885 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4481.62\n",
            "\n",
            "Epoch: 165\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.010 | Acc: 99.957% (25845/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.884 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4508.42\n",
            "\n",
            "Epoch: 166\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.46 | Loss: 0.010 | Acc: 99.957% (25845/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.887 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4535.09\n",
            "\n",
            "Epoch: 167\n",
            "0 100 Lap time (s): 0.18 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.46 | Loss: 0.010 | Acc: 99.973% (25849/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.879 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4561.80\n",
            "\n",
            "Epoch: 168\n",
            "0 100 Lap time (s): 0.18 | Loss: 0.008 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.010 | Acc: 99.969% (25848/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.870 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4588.59\n",
            "\n",
            "Epoch: 169\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.45 | Loss: 0.010 | Acc: 99.973% (25849/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.878 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 4615.27\n",
            "\n",
            "Epoch: 170\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.52 | Loss: 0.010 | Acc: 99.969% (25848/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.09 | Loss: 0.858 | Acc: 81.000% (81/100) | Best acc: 0.810\n",
            "Elapsed time: 4642.20\n",
            "\n",
            "Epoch: 171\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.010 | Acc: 99.981% (25851/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.864 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4669.06\n",
            "\n",
            "Epoch: 172\n",
            "0 100 Lap time (s): 0.17 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.54 | Loss: 0.010 | Acc: 99.977% (25850/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.870 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4695.92\n",
            "\n",
            "Epoch: 173\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.52 | Loss: 0.010 | Acc: 99.981% (25851/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.869 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4722.79\n",
            "\n",
            "Epoch: 174\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.52 | Loss: 0.009 | Acc: 99.977% (25850/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.09 | Loss: 0.861 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4749.69\n",
            "\n",
            "Epoch: 175\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.008 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.52 | Loss: 0.010 | Acc: 99.985% (25852/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.863 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4776.49\n",
            "\n",
            "Epoch: 176\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.52 | Loss: 0.010 | Acc: 99.988% (25853/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.870 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4803.27\n",
            "\n",
            "Epoch: 177\n",
            "0 100 Lap time (s): 0.18 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.50 | Loss: 0.009 | Acc: 99.981% (25851/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.869 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4829.95\n",
            "\n",
            "Epoch: 178\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.010 | Acc: 99.981% (25851/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.09 | Loss: 0.859 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4856.81\n",
            "\n",
            "Epoch: 179\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.010 | Acc: 99.977% (25850/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.867 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4883.57\n",
            "\n",
            "Epoch: 180\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.49 | Loss: 0.010 | Acc: 99.961% (25846/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.876 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4910.39\n",
            "\n",
            "Epoch: 181\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.008 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.010 | Acc: 99.977% (25850/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.876 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 4937.24\n",
            "\n",
            "Epoch: 182\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.010 | Acc: 99.961% (25846/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.892 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4964.08\n",
            "\n",
            "Epoch: 183\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.010 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.009 | Acc: 99.985% (25852/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.882 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 4990.85\n",
            "\n",
            "Epoch: 184\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.007 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.48 | Loss: 0.010 | Acc: 99.977% (25850/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.884 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 5017.68\n",
            "\n",
            "Epoch: 185\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.010 | Acc: 99.973% (25849/25856)\n",
            "Total activation density: 0.537\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.882 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 5044.35\n",
            "\n",
            "Epoch: 186\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.011 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.010 | Acc: 99.985% (25852/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.884 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 5071.17\n",
            "\n",
            "Epoch: 187\n",
            "0 100 Lap time (s): 0.16 | Loss: 0.008 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.009 | Acc: 99.973% (25849/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.861 | Acc: 77.000% (77/100) | Best acc: 0.810\n",
            "Elapsed time: 5097.91\n",
            "\n",
            "Epoch: 188\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.008 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.010 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.885 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 5124.69\n",
            "\n",
            "Epoch: 189\n",
            "0 100 Lap time (s): 0.14 | Loss: 0.008 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.009 | Acc: 99.985% (25852/25856)\n",
            "Total activation density: 0.535\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.890 | Acc: 79.000% (79/100) | Best acc: 0.810\n",
            "Elapsed time: 5151.49\n",
            "\n",
            "Epoch: 190\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.013 | Acc: 99.609% (255/256)\n",
            "100 100 Lap time (s): 11.51 | Loss: 0.010 | Acc: 99.965% (25847/25856)\n",
            "Total activation density: 0.536\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.875 | Acc: 80.000% (80/100) | Best acc: 0.810\n",
            "Elapsed time: 5178.42\n",
            "\n",
            "Epoch: 191\n",
            "0 100 Lap time (s): 0.13 | Loss: 0.009 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.55 | Loss: 0.010 | Acc: 99.946% (25842/25856)\n",
            "Total activation density: 0.534\n",
            "0 100 Lap time (s): 0.08 | Loss: 0.870 | Acc: 78.000% (78/100) | Best acc: 0.810\n",
            "Elapsed time: 5205.28\n",
            "\n",
            "Epoch: 192\n",
            "0 100 Lap time (s): 0.15 | Loss: 0.007 | Acc: 100.000% (256/256)\n",
            "100 100 Lap time (s): 11.53 | Loss: 0.010 | Acc: 99.969% (25848/25856)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6YqVQInmYyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_energy = fractional_layer_energies[:,0]\n",
        "conv1_energy = fractional_layer_energies[:,1]\n",
        "conv2_energy = fractional_layer_energies[:,2]\n",
        "conv3_energy = fractional_layer_energies[:,3]\n",
        "conv4_energy = fractional_layer_energies[:,4]\n",
        "conv5_energy = fractional_layer_energies[:,5]\n",
        "conv6_energy = fractional_layer_energies[:,6]\n",
        "conv7_energy = fractional_layer_energies[:,7]\n",
        "conv8_energy = fractional_layer_energies[:,8]\n",
        "conv9_energy = fractional_layer_energies[:,9]\n",
        "conv10_energy = fractional_layer_energies[:,10]\n",
        "conv11_energy = fractional_layer_energies[:,11]\n",
        "conv12_energy = fractional_layer_energies[:,12]\n",
        "conv13_energy = fractional_layer_energies[:,13]\n",
        "conv14_energy = fractional_layer_energies[:,14]\n",
        "conv15_energy = fractional_layer_energies[:,15]\n",
        "conv16_energy = fractional_layer_energies[:,16]\n",
        "conv17_energy = fractional_layer_energies[:,17]\n",
        "\n",
        "\n",
        "\n",
        "ylim = 1\n",
        "ylow = 0 \n",
        "\n",
        "fig = plt.figure(1, figsize=(15, 7), dpi=95)\n",
        "plt.subplot(231)\n",
        "plt.ylim(0, 1)\n",
        "plt.plot(test_acc, label = 'Test accuracy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(232)\n",
        "plt.ylim(ylow, ylim)\n",
        "plt.plot(total_energy, label = 'Total energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(233)\n",
        "plt.ylim(ylow, ylim)\n",
        "#plt.plot(conv1_energy, label = 'Conv1 energy')\n",
        "plt.plot(conv2_energy, label = 'Conv2 energy')\n",
        "plt.plot(conv3_energy, label = 'Conv3 energy')\n",
        "plt.plot(conv4_energy, label = 'Conv4 energy')\n",
        "plt.plot(conv5_energy, label = 'Conv5 energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(234)\n",
        "plt.ylim(ylow, ylim)\n",
        "plt.plot(conv6_energy, label = 'Conv6 energy')\n",
        "plt.plot(conv7_energy, label = 'Conv7 energy')\n",
        "plt.plot(conv8_energy, label = 'Conv8 energy')\n",
        "plt.plot(conv9_energy, label = 'Conv9 energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(235)\n",
        "plt.ylim(ylow, ylim)\n",
        "plt.plot(conv10_energy, label = 'Conv10 energy')\n",
        "plt.plot(conv11_energy, label = 'Conv11 energy')\n",
        "plt.plot(conv12_energy, label = 'Conv12 energy')\n",
        "plt.plot(conv13_energy, label = 'Conv13 energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(236)\n",
        "plt.ylim(ylow, ylim)\n",
        "plt.plot(conv14_energy, label = 'Conv14 energy')\n",
        "plt.plot(conv15_energy, label = 'Conv15 energy')\n",
        "plt.plot(conv16_energy, label = 'Conv16 energy')\n",
        "plt.plot(conv17_energy, label = 'Conv17 energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "\n",
        "fig.suptitle('Fractional activation energy (sparsity) vs. epoch', fontsize = 16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4kGE624ncW5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs -1 =50\n",
        "\n",
        "size_1 = int(fractional_layer_energies[num_epochs-1, 1] * 64)\n",
        "size_2 = int(fractional_layer_energies[num_epochs-1, 2] * 64)\n",
        "size_3 = int(fractional_layer_energies[num_epochs-1, 3] * 64)\n",
        "size_4 = int(fractional_layer_energies[num_epochs-1, 4] * 64)\n",
        "size_5 = int(fractional_layer_energies[num_epochs-1, 5] * 64)\n",
        "size_6 = int(fractional_layer_energies[num_epochs-1, 6] * 128)\n",
        "size_7 = int(fractional_layer_energies[num_epochs-1, 7] * 128)\n",
        "size_8 = int(fractional_layer_energies[num_epochs-1, 8] * 128)\n",
        "size_9 = int(fractional_layer_energies[num_epochs-1, 9] * 128)\n",
        "size_10 = int(fractional_layer_energies[num_epochs-1, 10] * 256)\n",
        "size_11 = int(fractional_layer_energies[num_epochs-1, 11] * 256)\n",
        "size_12 = int(fractional_layer_energies[num_epochs-1, 12] * 256)\n",
        "size_13 = int(fractional_layer_energies[num_epochs-1, 13] * 256)\n",
        "size_14 = int(fractional_layer_energies[num_epochs-1, 14] * 512)\n",
        "size_15 = int(fractional_layer_energies[num_epochs-1, 15] * 512)\n",
        "size_16 = int(fractional_layer_energies[num_epochs-1, 16] * 512)\n",
        "size_17 = int(fractional_layer_energies[num_epochs-1, 17] * 512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBlgvcVtnz2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net1(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, size_1, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm1 = nn.BatchNorm2d(size_1)\n",
        "\n",
        "        # BLOCK 1 #\n",
        "        self.conv2 = nn.Conv2d(size_1, size_2, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm2 = nn.BatchNorm2d(size_2)\n",
        "        self.conv3 = nn.Conv2d(size_2, size_3, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm3 = nn.BatchNorm2d(size_3)\n",
        "        self.shortcut1 = nn.Conv2d(size_1, size_3, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS1 = nn.BatchNorm2d(size_3)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(size_3, size_4, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm4 = nn.BatchNorm2d(size_4)\n",
        "        self.conv5 = nn.Conv2d(size_4, size_5, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm5 = nn.BatchNorm2d(size_5)\n",
        "        self.shortcut2 = nn.Conv2d(size_3, size_5, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS2 = nn.BatchNorm2d(size_5)\n",
        "\n",
        "\n",
        "        # BLOCK 2 #\n",
        "        self.conv6 = nn.Conv2d(size_5, size_6, kernel_size = 3, stride = 2, padding = 1, bias = False)\n",
        "        self.norm6 = nn.BatchNorm2d(size_6)\n",
        "        self.conv7 = nn.Conv2d(size_6, size_7, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm7 = nn.BatchNorm2d(size_7)\n",
        "        self.shortcut3 = nn.Conv2d(size_5, size_7, kernel_size = 1, stride = 2, padding = 0, bias = False)\n",
        "        self.normS3 = nn.BatchNorm2d(size_7)\n",
        "        \n",
        "        self.conv8 = nn.Conv2d(size_7, size_8, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm8 = nn.BatchNorm2d(size_8)\n",
        "        self.conv9 = nn.Conv2d(size_8, size_9, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm9 = nn.BatchNorm2d(size_9)\n",
        "        self.shortcut4 = nn.Conv2d(size_7, size_9, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS4 = nn.BatchNorm2d(size_9)\n",
        "\n",
        "\n",
        "        # BLOCK 3 #\n",
        "        self.conv10 = nn.Conv2d(size_9, size_10, kernel_size = 3, stride = 2, padding = 1, bias = False)\n",
        "        self.norm10 = nn.BatchNorm2d(size_10)\n",
        "        self.conv11 = nn.Conv2d(size_10, size_11, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm11 = nn.BatchNorm2d(size_11)\n",
        "        self.shortcut5 = nn.Conv2d(size_9, size_11, kernel_size = 1, stride = 2, padding = 0, bias = False)\n",
        "        self.normS5 = nn.BatchNorm2d(size_11)\n",
        "        \n",
        "        self.conv12 = nn.Conv2d(size_11, size_12, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm12 = nn.BatchNorm2d(size_12)\n",
        "        self.conv13 = nn.Conv2d(size_12, size_13, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm13 = nn.BatchNorm2d(size_13)\n",
        "        self.shortcut6 = nn.Conv2d(size_11, size_13, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS6 = nn.BatchNorm2d(size_13)\n",
        "\n",
        "\n",
        "        # BLOCK 4 #\n",
        "        self.conv14 = nn.Conv2d(size_13, size_14, kernel_size = 3, stride = 2, padding = 1, bias = False)\n",
        "        self.norm14 = nn.BatchNorm2d(size_14)\n",
        "        self.conv15 = nn.Conv2d(size_14, size_15, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm15 = nn.BatchNorm2d(size_15)\n",
        "        self.shortcut7 = nn.Conv2d(size_13, size_15, kernel_size = 1, stride = 2, padding = 0, bias = False)\n",
        "        self.normS7 = nn.BatchNorm2d(size_15)\n",
        "        \n",
        "        self.conv16 = nn.Conv2d(size_15, size_16, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm16 = nn.BatchNorm2d(size_16)\n",
        "        self.conv17 = nn.Conv2d(size_16, size_17, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.norm17 = nn.BatchNorm2d(size_17)\n",
        "        self.shortcut8 = nn.Conv2d(size_15, size_17, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.normS8 = nn.BatchNorm2d(size_17)\n",
        "\n",
        "        self.linear = nn.Linear(size_17, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x0):\n",
        "        x1 = F.relu(self.norm1(self.conv1(x0)))        # x1 has size 64 (i.e. it has 64 filters)\n",
        "\n",
        "        # BLOCK 1 #\n",
        "        x2 = F.relu(self.norm2(self.conv2(x1)))         # x2 has size 64\n",
        "        x3 = F.relu(self.norm3(self.conv3(x2)))         # x3 has size 64\n",
        "        xS1 = F.relu(self.normS1(self.shortcut1(x1)))   # have to project x1 to have the same size as x3\n",
        "        x3 = x3 + xS1                                   \n",
        "        x4 = F.relu(self.norm4(self.conv4(x3)))         # x4 has size 64\n",
        "        x5 = F.relu(self.norm5(self.conv5(x4)))         # x5 has size 64\n",
        "        xS2 = F.relu(self.normS2(self.shortcut2(x3)))   # have to project x3 to have the same size as x5\n",
        "        x5 = x5 + xS2\n",
        "        \n",
        "\n",
        "        # BLOCK 2 #\n",
        "        x6 = F.relu(self.norm6(self.conv6(x5)))         # x6 has size 128\n",
        "        x7 = F.relu(self.norm7(self.conv7(x6)))         # x7 has size 128\n",
        "        xS3 = F.relu(self.normS3(self.shortcut3(x5)))   # have to project x5 to have the same size as x7\n",
        "        x7 = x7 + xS3\n",
        "        x8 = F.relu(self.norm8(self.conv8(x7)))         # x8 has size 128\n",
        "        x9 = F.relu(self.norm9(self.conv9(x8)))         # x9 has size 128\n",
        "        xS4 = F.relu(self.normS4(self.shortcut4(x7)))   # have to project x7 to have the same size as x9\n",
        "        x9 = x9 + xS4\n",
        "\n",
        "        # BLOCK 3 #\n",
        "        x10 = F.relu(self.norm10(self.conv10(x9)))      # x10 has size 256\n",
        "        x11 = F.relu(self.norm11(self.conv11(x10)))     # x11 has size 256\n",
        "        xS5 = F.relu(self.normS5(self.shortcut5(x9)))   # have to project x9 to have the same size as x11\n",
        "        x11 = x11 + xS5\n",
        "        x12 = F.relu(self.norm12(self.conv12(x11)))     # x12 has size 256\n",
        "        x13 = F.relu(self.norm13(self.conv13(x12)))     # x13 has size 256\n",
        "        xS6 = F.relu(self.normS6(self.shortcut6(x11)))  # have to project x11 to have the same size as x13\n",
        "        x13 = x13 + xS6\n",
        "\n",
        "        # BLOCK 4 #\n",
        "        x14 = F.relu(self.norm14(self.conv14(x13)))     # x14 has size 512\n",
        "        x15 = F.relu(self.norm15(self.conv15(x14)))     # x15 has size 512\n",
        "        xS7 = F.relu(self.normS7(self.shortcut7(x13)))  # have to project x13 to have the same size as x15\n",
        "        x15 = x15 + xS7\n",
        "        x16 = F.relu(self.norm16(self.conv16(x15)))     # x16 has size 512\n",
        "        x17 = F.relu(self.norm17(self.conv17(x16)))     # x17 has size 512\n",
        "        xS8 = F.relu(self.normS8(self.shortcut8(x15)))  # have to project x15 to have the same size as x17\n",
        "        x17 = x17 + xS8\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePr-lv5cn2Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''train network 1'''\n",
        "\n",
        "device = 'cuda'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "num_epochs = 210\n",
        "num_layers = 17\n",
        "\n",
        "absolute_layer_energies1 = np.zeros((num_epochs, num_layers+1))\n",
        "fractional_layer_energies1 = np.zeros((num_epochs, num_layers+1))\n",
        "\n",
        "\n",
        "print('==> Building model..')\n",
        "net1 = Net1()\n",
        "net1 = net1.to(device)\n",
        "net1 = torch.nn.DataParallel(net1)\n",
        "cudnn.benchmark = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net1.parameters(), lr=0.08, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net1.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    activations = []\n",
        "    # global absolute_layer_energies\n",
        "    # global fractional_layer_energies\n",
        "    previous_time = time.process_time()\n",
        "    \n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs, activations = net1(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        acc = correct/total    \n",
        "        if batch_idx%100==0:\n",
        "            current_time = time.process_time()\n",
        "            print(batch_idx, len(testloader), 'Lap time (s): %.2f | Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                    % (current_time - previous_time, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "            previous_time = current_time\n",
        "            \n",
        "    this_epoch_abs_energies, this_epoch_frac_energies = count_non_zeros(activations)\n",
        "    fractional_layer_energies1[epoch] = this_epoch_frac_energies\n",
        "    absolute_layer_energies1[epoch] = this_epoch_abs_energies\n",
        "    print('Total activation density: %.3f' % (fractional_layer_energies1[epoch, 0]))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net1.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    activations = []\n",
        "    previous_time = time.process_time()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs, activations = net1(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            acc = correct/total\n",
        "            if batch_idx%100 == 0:\n",
        "                best_acc = max(acc, best_acc)\n",
        "                current_time = time.process_time()\n",
        "                print(batch_idx, len(testloader), 'Lap time (s): %.2f | Loss: %.3f | Acc: %.3f%% (%d/%d) | Best acc: %.3f'\n",
        "                    % (current_time - previous_time, test_loss/(batch_idx+1), 100.*correct/total, correct, total, best_acc))\n",
        "                previous_time = current_time\n",
        "            if acc>=best_acc:\n",
        "                #print('Saving')\n",
        "                torch.save(net.state_dict(),'./sample_data/resnet18_net1.pth')\n",
        "\n",
        "\n",
        "def count_non_zeros(activations): \n",
        "    \n",
        "    #returns: numpy array containing the number of non-zero activations per layer (15x1)\n",
        "    #         numpy array containing the fraction of non-zero activations per layer (15x1)\n",
        "    \n",
        "    n = 0\n",
        "    num_zeros = np.zeros((num_layers+1,), dtype = int)\n",
        "    num_non_zeros = np.zeros((num_layers+1,), dtype = int)\n",
        "    total_activations = np.zeros((num_layers+1,), dtype = int)\n",
        "    fraction_non_zero = np.zeros((num_layers+1,), dtype = float)\n",
        "    for x in activations:\n",
        "        n += 1\n",
        "        #reshape activations into a flat list\n",
        "        num_activations = x.size()[0] * x.size()[1] * x.size()[2] * x.size()[3]\n",
        "        \n",
        "        y = x.view(num_activations).tolist()\n",
        "        \n",
        "        #count how many entries are zero / non-zero\n",
        "        num_zeros[n] = y.count(0)\n",
        "        total_activations[n] = num_activations\n",
        "        num_non_zeros[n] = len(y) - num_zeros[n]\n",
        "        fraction_non_zero[n] = num_non_zeros[n].astype(float)/float(len(y))\n",
        "\n",
        "        \n",
        "    #store total values in the zero slot\n",
        "    num_non_zeros[0] = np.sum(num_non_zeros) \n",
        "    total_activations[0] = np.sum(total_activations)\n",
        "    fraction_non_zero[0] = num_non_zeros[0].astype(float)/total_activations[0].astype(float)\n",
        "    return num_non_zeros, fraction_non_zero\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    if (epoch == 70):\n",
        "        optimizer = optim.SGD(net1.parameters(), lr=0.005, momentum=0.9, weight_decay=5e-4)\n",
        "    if (epoch == 140):\n",
        "        optimizer = optim.SGD(net1.parameters(), lr=0.0005, momentum=0.9, weight_decay=5e-4)\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    print('Elapsed time: %.2f' % (time.process_time()))\n",
        "\n",
        "\n",
        "torch.save(fractional_layer_energies1,'./sample_data/fraction_energy_net1.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNL48y67oZUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_energy = fractional_layer_energies[:,0]\n",
        "conv1_energy = fractional_layer_energies[:,1]\n",
        "conv2_energy = fractional_layer_energies[:,2]\n",
        "conv3_energy = fractional_layer_energies[:,3]\n",
        "conv4_energy = fractional_layer_energies[:,4]\n",
        "conv5_energy = fractional_layer_energies[:,5]\n",
        "conv6_energy = fractional_layer_energies[:,6]\n",
        "conv7_energy = fractional_layer_energies[:,7]\n",
        "conv8_energy = fractional_layer_energies[:,8]\n",
        "conv9_energy = fractional_layer_energies[:,9]\n",
        "conv10_energy = fractional_layer_energies[:,10]\n",
        "conv11_energy = fractional_layer_energies[:,11]\n",
        "conv12_energy = fractional_layer_energies[:,12]\n",
        "conv13_energy = fractional_layer_energies[:,13]\n",
        "conv14_energy = fractional_layer_energies[:,14]\n",
        "conv15_energy = fractional_layer_energies[:,15]\n",
        "conv16_energy = fractional_layer_energies[:,16]\n",
        "conv17_energy = fractional_layer_energies[:,17]\n",
        "\n",
        "\n",
        "\n",
        "ylim = 1\n",
        "ylow = 0 \n",
        "\n",
        "fig = plt.figure(1, figsize=(15, 7), dpi=95)\n",
        "#plt.subplot(231)\n",
        "#plt.ylim(0, 1)\n",
        "#plt.plot(test_acc, label = 'Test accuracy')\n",
        "#plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(232)\n",
        "plt.ylim(ylow, ylim)\n",
        "plt.plot(total_energy, label = 'Total energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(233)\n",
        "plt.ylim(ylow, ylim)\n",
        "#plt.plot(conv1_energy, label = 'Conv1 energy')\n",
        "plt.plot(conv2_energy, label = 'Conv2 energy')\n",
        "plt.plot(conv3_energy, label = 'Conv3 energy')\n",
        "plt.plot(conv4_energy, label = 'Conv4 energy')\n",
        "plt.plot(conv5_energy, label = 'Conv5 energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(234)\n",
        "plt.ylim(ylow, ylim)\n",
        "plt.plot(conv6_energy, label = 'Conv6 energy')\n",
        "plt.plot(conv7_energy, label = 'Conv7 energy')\n",
        "plt.plot(conv8_energy, label = 'Conv8 energy')\n",
        "plt.plot(conv9_energy, label = 'Conv9 energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(235)\n",
        "plt.ylim(ylow, ylim)\n",
        "plt.plot(conv10_energy, label = 'Conv10 energy')\n",
        "plt.plot(conv11_energy, label = 'Conv11 energy')\n",
        "plt.plot(conv12_energy, label = 'Conv12 energy')\n",
        "plt.plot(conv13_energy, label = 'Conv13 energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "plt.subplot(236)\n",
        "plt.ylim(ylow, ylim)\n",
        "plt.plot(conv14_energy, label = 'Conv14 energy')\n",
        "plt.plot(conv15_energy, label = 'Conv15 energy')\n",
        "plt.plot(conv16_energy, label = 'Conv16 energy')\n",
        "plt.plot(conv17_energy, label = 'Conv17 energy')\n",
        "plt.legend(frameon = False)\n",
        "\n",
        "\n",
        "fig.suptitle('Fractional activation energy (sparsity) vs. epoch', fontsize = 16)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}